{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [1., 0.],\n",
      "        [2., 1.],\n",
      "        [0., 2.]], requires_grad=True)\n",
      "tensor([[-1.2500,  1.0000,  0.0000,  0.2500],\n",
      "        [ 1.0000, -1.8333,  0.6667,  0.1667],\n",
      "        [ 0.0000,  0.6667, -0.8333,  0.1667],\n",
      "        [ 0.2500,  0.1667,  0.1667, -0.5833]], grad_fn=<CopySlices>)\n",
      "tensor(12., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import math\n",
    "from scipy.spatial import ConvexHull\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_triangulation (points, triang):\n",
    "    plt.triplot (points[:,0], points[:,1], triang)\n",
    "    plt.plot (points[:,0], points[:,1], 'o')\n",
    "    plt.show()\n",
    "\n",
    "def calc_L (points, simplices):\n",
    "    #simplices = Delaunay (points).simplices\n",
    "    #distances = euclidean_distances (points, points)\n",
    "    \n",
    "    L = torch.zeros((len(points), len(points)))\n",
    "\n",
    "    for sim in simplices:\n",
    "        for ind in [[0, 1], [1, 2], [0, 2]]:\n",
    "            #L [sim [ind [0]], sim [ind [1]]] = distances [sim [ind [0]], sim [ind [1]]]\n",
    "            #L [sim [ind [1]], sim [ind [0]]] = distances [sim [ind [1]], sim [ind [0]]]\n",
    "            L [sim [ind [0]], sim [ind [1]]] = ((points[sim [ind [0]]][0]-points[sim [ind [1]]][0])**2+\\\n",
    "                                               (points[sim [ind [0]]][1]-points[sim [ind [1]]][1])**2)**0.5\n",
    "            L [sim [ind [1]], sim [ind [0]]] = ((points[sim [ind [0]]][0]-points[sim [ind [1]]][0])**2+\\\n",
    "                                               (points[sim [ind [0]]][1]-points[sim [ind [1]]][1])**2)**0.5\n",
    "\n",
    "    return L\n",
    "\n",
    "def calc_triangle_area (L, i1, i2, i3):\n",
    "    l1 = L [i1, i2]\n",
    "    l2 = L [i2, i3]\n",
    "    l3 = L [i3, i1]\n",
    "\n",
    "    p = (l1 + l2 + l3) / 2\n",
    "\n",
    "    return math.sqrt (p * (p - l1) * (p - l2) * (p - l3))\n",
    "\n",
    "def calc_A (simplices, L, points_num):\n",
    "    A = torch.zeros ((points_num, points_num))\n",
    "    \n",
    "    for i in range (points_num):\n",
    "        area = 0\n",
    "        \n",
    "        for j in range (len (simplices)):\n",
    "            if (i in simplices [j]):\n",
    "                sim = simplices [j]\n",
    "                \n",
    "                area_part = calc_triangle_area (L, sim [0], sim [1], sim [2])\n",
    "                \n",
    "                area += area_part / 3\n",
    "        \n",
    "        A [i, i] = area\n",
    "    \n",
    "    return A\n",
    "\n",
    "def find_E_Eb (points, simplices):\n",
    "    E = []\n",
    "    \n",
    "    for sim in simplices:\n",
    "        E.append (sorted ((sim [0], sim [1])))\n",
    "        E.append (sorted ((sim [1], sim [2])))\n",
    "        E.append (sorted ((sim [2], sim [0])))\n",
    "    \n",
    "    E_b = []\n",
    "    hull = ConvexHull (points).vertices\n",
    "    \n",
    "    for i in range (len (hull) - 1):\n",
    "        E_b.append (sorted ((hull [i], hull [i + 1])))\n",
    "    \n",
    "    E_b.append (sorted ((hull [0], hull [-1])))\n",
    "    \n",
    "    #АЛАРМА\n",
    "    #Тут нужно оставить в E и E_b только уникальные таплы.\n",
    "    #Я попробовал это сделать, но с unhashable type какая-то морока, так то я забил.\n",
    "    #В этом месте числа внутри тапла отсортированы.\n",
    "    #Пробовал вот таким образом:\n",
    "    #return list (set (E)), list (set (E_b))\n",
    "    \n",
    "    return E, E_b\n",
    "\n",
    "def calc_W (E, E_b, A, L, simplices):\n",
    "    W = torch.zeros (A.shape)\n",
    "    \n",
    "    sh = W.shape\n",
    "    \n",
    "    for i in range (sh [0]):\n",
    "        for j in range (i + 1, sh [0]):\n",
    "            kh_list = []\n",
    "    \n",
    "            for sim in simplices:\n",
    "                elem = set (sim)                \n",
    "                ele = set ([i, j])\n",
    "                \n",
    "                #print (\"ele, elem\")\n",
    "                #print (ele, elem)\n",
    "                \n",
    "                if (ele.issubset (elem)):\n",
    "                    kh_list.append (elem.difference (ele))\n",
    "            \n",
    "            if (len (kh_list) == 0):\n",
    "                continue\n",
    "            \n",
    "            h = list (kh_list [0]) [0]\n",
    "            \n",
    "            if ([i, j] in E and [i, j] not in E_b):\n",
    "                k = list (kh_list [1]) [0]\n",
    "                \n",
    "                val = 0\n",
    "                \n",
    "                val += (- L [i, j]**2 + L [j, k]**2 + L [k, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, k))\n",
    "\n",
    "                val += (- L [i, j]**2 + L [j, h]**2 + L [h, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, h))\n",
    "                \n",
    "                W [i, j] = val\n",
    "                \n",
    "            elif ([i, j] in E_b):\n",
    "                val = 0\n",
    "                \n",
    "                val += (- L [i, j]**2 + L [j, h]**2 + L [h, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, h))\n",
    "                \n",
    "                W [i, j] = val\n",
    "        \n",
    "    for i in range (sh [0]):\n",
    "        for j in range (i, sh [0]):\n",
    "            W [j] [i] = W [i] [j]\n",
    "    \n",
    "    for i in range (sh [0]):\n",
    "        W [i, i] = - sum (W [i, :])\n",
    "\n",
    "    return W\n",
    "\n",
    "def find_eig (A):\n",
    "    n, m = A.shape\n",
    "\n",
    "    #Q = np.eye(n)\n",
    "    #R = A.astype(np.float64).copy()\n",
    "    \n",
    "    Q = torch.eye (n)\n",
    "    R = A.clone ()\n",
    "    \n",
    "    for i in range(m):\n",
    "        x = R[i:, i].clone()\n",
    "        \n",
    "        #u = x[:, np.newaxis]\n",
    "        u = x.unsqueeze (1)\n",
    "        \n",
    "        #alpha = np.linalg.norm(u)\n",
    "        alpha = u.detach().numpy()\n",
    "        \n",
    "        u[0] -= alpha\n",
    "        v = u / np.linalg.norm(u)\n",
    "        \n",
    "        H = np.eye(n - i) - 2 * v.dot(v.conj().T)\n",
    "        \n",
    "        H = np.concatenate([np.zeros([n - i, i]), H], axis=1)\n",
    "        H = np.concatenate([np.eye(i, n), H], axis=0)\n",
    "\n",
    "        R = H.dot(R)\n",
    "        Q = Q.dot(H)\n",
    "\n",
    "    #return Q[:, :m], R[:m]\n",
    "    \n",
    "    eigs = []\n",
    "    \n",
    "    for i in range (n):\n",
    "        eigs.append (R [i, i])\n",
    "    \n",
    "    return eigs\n",
    "\n",
    "def modified_gram_schmidt_qr(A): # 5 pts\n",
    "    Q = torch.zeros((A.shape[0], A.shape[1])) #saaas\n",
    "    R = torch.zeros((A.shape[1], A.shape[1]))\n",
    "    \n",
    "    #initialization\n",
    "    Q[:, :A.shape[1]] = A[:, :A.shape[1]].clone()\n",
    "    \n",
    "    #Q building with G-S ortagonalization\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(i):\n",
    "            Q[:, i] = Q[:, i].clone()-Q[:, i].clone() @ Q[:, j].clone()*Q[:, j].clone()\n",
    "        shit1 = torch.norm(Q[:, i]).clone()\n",
    "        shit2 = Q[:, i].clone()/shit1\n",
    "        Q[:, i] = shit2.clone()\n",
    "    \n",
    "    #R building\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(i+1):\n",
    "            R[j, i] = Q[:, j].clone() @(A[:, i]).clone()\n",
    "    \n",
    "    return Q, R\n",
    "\n",
    "def modified_gram_schmidt_qr_(A): # 5 pts\n",
    "    assert A.shape[0] >= A.shape[1], 'm is not >= n'\n",
    "    new_vectors = torch.zeros(A.shape)\n",
    "    for i in range(A.shape[1]):\n",
    "        new_vectors[:,i] += A[:,i]\n",
    "        if i > 0:\n",
    "            new_vectors[:,i] -= torch.tensor(((A[:,i] @ new_vectors[:,0])/(new_vectors[:,0] @ new_vectors[:,0])) * new_vectors[:,0])\n",
    "        \n",
    "        for j in range(1,i):\n",
    "            new_vectors[:,i] -= torch.tensor(((new_vectors[:,i] @ new_vectors[:,j])/(new_vectors[:,j] @ new_vectors[:,j])) * new_vectors[:,j])\n",
    "        \n",
    "    # normalization\n",
    "    for i in range(new_vectors.shape[1]):\n",
    "        new_vectors[:,i] /= torch.tensor(new_vectors[:,i]).norm()\n",
    "    Q = new_vectors\n",
    "    R = torch.zeros((A.shape[1],A.shape[1]))\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(i, A.shape[1]):\n",
    "            R[i,j] += A[:,j] @ new_vectors[:,i]\n",
    "    return Q, R\n",
    "\n",
    "def find_eigenvalues (W, A):\n",
    "    product = torch.inverse(a) @ \\\n",
    "W\n",
    "    #lambdas, vectors = tuple (torch.symeig (product, eigenvectors=True))\n",
    "    #lambdas, vectors = tuple (torch.eig (product, eigenvectors=True))\n",
    "\n",
    "    Q, R = modified_gram_schmidt_qr_ (product)\n",
    "    \n",
    "    eigen = torch.diag(R)\n",
    "    #eigen[-1]=0\n",
    "    \n",
    "    return eigen#, vectors\n",
    "\n",
    "def cut (val):\n",
    "    return (min (0, val))**2\n",
    "\n",
    "def rho (V, L, E_b, simplices):\n",
    "    rho_1 = 0\n",
    "    \n",
    "    for e in E_b:\n",
    "        rho_1 += L [e [0], e [1]]**2\n",
    "    \n",
    "    rho_2 = 0\n",
    "    \n",
    "    for s in simplices:\n",
    "        for sim in list(itertools.permutations(s)):\n",
    "\n",
    "            rot_matr = torch.tensor ([[0., -1.], [1., 0.]])\n",
    "            sub_1 = V [sim [1]] - V [sim [0]]\n",
    "            sub_2 = V [sim [2]] - V [sim [0]]\n",
    "\n",
    "            curr_val = (rot_matr @ sub_1).transpose(0, -1) @ sub_2\n",
    "\n",
    "            rho_2 += curr_val\n",
    "    \n",
    "    rho = rho_1 + cut (rho_2)\n",
    "    \n",
    "    return rho\n",
    "\n",
    "def weighted_norm (a, b):\n",
    "    norm = 0\n",
    "    \n",
    "    for i in range (len (a)):\n",
    "        norm += (a [i] - b [i])**2 / (i + 1)\n",
    "    \n",
    "    return norm\n",
    "\n",
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 2.0)]\n",
    "points = torch.tensor(initial, requires_grad=True)\n",
    "\n",
    "#points = np.array([[0, 0], [1, 0], [2, 0], [0, 2]])\n",
    "    \n",
    "#points = np.random.rand (6, 2)\n",
    "\n",
    "print (points)\n",
    "\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "\n",
    "L = calc_L (points, simplices)\n",
    "#print (L)\n",
    "\n",
    "A = calc_A (simplices, L, len (points))\n",
    "\n",
    "#print (A)\n",
    "\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "\n",
    "#print (E)\n",
    "#print (\"\\n\")\n",
    "#print (E_b)\n",
    "\n",
    "W = calc_W (E, E_b, A, L, simplices)\n",
    "\n",
    "print (W)\n",
    "\n",
    "pen = rho (points, L, E_b, simplices)\n",
    "\n",
    "print (pen)\n",
    "\n",
    "#plot_triangulation (points, simplices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = torch.inverse (A) @ W\n",
    "    \n",
    "    #lambdas, vectors = tuple (torch.symeig (product, eigenvectors=True))\n",
    "    #lambdas, vectors = tuple (torch.eig (product, eigenvectors=True))\n",
    "\n",
    "Q, R = modified_gram_schmidt_qr (product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.9487,  1.8415,  0.8187, -0.7330], grad_fn=<DiagBackward>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9497, -0.1771, -0.0572,  0.2520],\n",
       "         [ 0.3039, -0.6167, -0.3613,  0.6299],\n",
       "         [ 0.0000,  0.7241, -0.5770,  0.3780],\n",
       "         [ 0.0760,  0.2531,  0.7303,  0.6299]], grad_fn=<QrBackward>),\n",
       " tensor([[ 3.9487e+00, -3.5024e+00,  2.5831e-01, -7.0466e-01],\n",
       "         [ 0.0000e+00,  1.8415e+00, -1.6495e+00, -1.9198e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  8.1867e-01, -8.1867e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3842e-07]],\n",
       "        grad_fn=<QrBackward>))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.qr(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_getri_single is not implemented for type torch.LongTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-b3fb475831a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_A\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msimplices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_W\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_eigenvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-280-2393065390b4>\u001b[0m in \u001b[0;36mfind_eigenvalues\u001b[0;34m(W, A)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_eigenvalues\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;31m#lambdas, vectors = tuple (torch.symeig (product, eigenvectors=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_getri_single is not implemented for type torch.LongTensor"
     ]
    }
   ],
   "source": [
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 2.0)]\n",
    "\n",
    "#initial = torch.rand (15, 2)\n",
    "\n",
    "target = torch.tensor(initial)\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "L = calc_L (target, simplices)\n",
    "A = calc_A (simplices, L, len (points))\n",
    "W = calc_W (E, E_b, A, L, simplices)\n",
    "mu = find_eigenvalues(W, A)\n",
    "print (E, E_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kefir/miniconda3/envs/zenv/lib/python3.7/site-packages/ipykernel_launcher.py:205: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/kefir/miniconda3/envs/zenv/lib/python3.7/site-packages/ipykernel_launcher.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/kefir/miniconda3/envs/zenv/lib/python3.7/site-packages/ipykernel_launcher.py:212: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23700.9727, grad_fn=<AddBackward0>)\n",
      "tensor(23688.1543, grad_fn=<AddBackward0>)\n",
      "tensor(23698.7676, grad_fn=<AddBackward0>)\n",
      "tensor(23645.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23629.1230, grad_fn=<AddBackward0>)\n",
      "tensor(23617.7246, grad_fn=<AddBackward0>)\n",
      "tensor(23632.9277, grad_fn=<AddBackward0>)\n",
      "tensor(23715.7422, grad_fn=<AddBackward0>)\n",
      "tensor(23685.4824, grad_fn=<AddBackward0>)\n",
      "tensor(23639.2773, grad_fn=<AddBackward0>)\n",
      "tensor(23636.9805, grad_fn=<AddBackward0>)\n",
      "tensor(23670.9531, grad_fn=<AddBackward0>)\n",
      "tensor(23638.9297, grad_fn=<AddBackward0>)\n",
      "tensor(23726.6504, grad_fn=<AddBackward0>)\n",
      "tensor(23706.2148, grad_fn=<AddBackward0>)\n",
      "tensor(23725.0586, grad_fn=<AddBackward0>)\n",
      "tensor(23732.3340, grad_fn=<AddBackward0>)\n",
      "tensor(23642.6895, grad_fn=<AddBackward0>)\n",
      "tensor(23634.3027, grad_fn=<AddBackward0>)\n",
      "tensor(23672.5508, grad_fn=<AddBackward0>)\n",
      "tensor(23694.8945, grad_fn=<AddBackward0>)\n",
      "tensor(23718.0254, grad_fn=<AddBackward0>)\n",
      "tensor(23683.6582, grad_fn=<AddBackward0>)\n",
      "tensor(23667.6133, grad_fn=<AddBackward0>)\n",
      "tensor(23737.7910, grad_fn=<AddBackward0>)\n",
      "tensor(23663.4922, grad_fn=<AddBackward0>)\n",
      "tensor(23732.2305, grad_fn=<AddBackward0>)\n",
      "tensor(23663.8613, grad_fn=<AddBackward0>)\n",
      "tensor(23723.1523, grad_fn=<AddBackward0>)\n",
      "tensor(23717.2617, grad_fn=<AddBackward0>)\n",
      "tensor(23732.8027, grad_fn=<AddBackward0>)\n",
      "tensor(23749.7188, grad_fn=<AddBackward0>)\n",
      "tensor(23678.0547, grad_fn=<AddBackward0>)\n",
      "tensor(23679.0508, grad_fn=<AddBackward0>)\n",
      "tensor(23664.0938, grad_fn=<AddBackward0>)\n",
      "tensor(23676.6797, grad_fn=<AddBackward0>)\n",
      "tensor(23756.6875, grad_fn=<AddBackward0>)\n",
      "tensor(23746.3125, grad_fn=<AddBackward0>)\n",
      "tensor(23752.2852, grad_fn=<AddBackward0>)\n",
      "tensor(23728.3398, grad_fn=<AddBackward0>)\n",
      "tensor(23678.7695, grad_fn=<AddBackward0>)\n",
      "tensor(23723.4922, grad_fn=<AddBackward0>)\n",
      "tensor(23752.6113, grad_fn=<AddBackward0>)\n",
      "tensor(23678.1113, grad_fn=<AddBackward0>)\n",
      "tensor(23676.8379, grad_fn=<AddBackward0>)\n",
      "tensor(23739.4160, grad_fn=<AddBackward0>)\n",
      "tensor(23745.1875, grad_fn=<AddBackward0>)\n",
      "tensor(23726.3867, grad_fn=<AddBackward0>)\n",
      "tensor(23744.4434, grad_fn=<AddBackward0>)\n",
      "tensor(23683.3281, grad_fn=<AddBackward0>)\n",
      "tensor(23704.2617, grad_fn=<AddBackward0>)\n",
      "tensor(23761.2402, grad_fn=<AddBackward0>)\n",
      "tensor(23753.9434, grad_fn=<AddBackward0>)\n",
      "tensor(23736.6250, grad_fn=<AddBackward0>)\n",
      "tensor(23689.5117, grad_fn=<AddBackward0>)\n",
      "tensor(23757.9746, grad_fn=<AddBackward0>)\n",
      "tensor(23697.2949, grad_fn=<AddBackward0>)\n",
      "tensor(23742.1094, grad_fn=<AddBackward0>)\n",
      "tensor(23692.2285, grad_fn=<AddBackward0>)\n",
      "tensor(23778.1992, grad_fn=<AddBackward0>)\n",
      "tensor(23690.1094, grad_fn=<AddBackward0>)\n",
      "tensor(23684.5605, grad_fn=<AddBackward0>)\n",
      "tensor(23775.7852, grad_fn=<AddBackward0>)\n",
      "tensor(23785.7578, grad_fn=<AddBackward0>)\n",
      "tensor(23706.0605, grad_fn=<AddBackward0>)\n",
      "tensor(23771.8320, grad_fn=<AddBackward0>)\n",
      "tensor(23780.7578, grad_fn=<AddBackward0>)\n",
      "tensor(23690.2363, grad_fn=<AddBackward0>)\n",
      "tensor(23707.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23699.0312, grad_fn=<AddBackward0>)\n",
      "tensor(23739.2246, grad_fn=<AddBackward0>)\n",
      "tensor(23794.3496, grad_fn=<AddBackward0>)\n",
      "tensor(23781.8242, grad_fn=<AddBackward0>)\n",
      "tensor(23770.7422, grad_fn=<AddBackward0>)\n",
      "tensor(23701.4375, grad_fn=<AddBackward0>)\n",
      "tensor(23796.2969, grad_fn=<AddBackward0>)\n",
      "tensor(23768.0117, grad_fn=<AddBackward0>)\n",
      "tensor(23774.6992, grad_fn=<AddBackward0>)\n",
      "tensor(23731.9902, grad_fn=<AddBackward0>)\n",
      "tensor(23707.5254, grad_fn=<AddBackward0>)\n",
      "tensor(23761.5508, grad_fn=<AddBackward0>)\n",
      "tensor(23707.5371, grad_fn=<AddBackward0>)\n",
      "tensor(23712.3125, grad_fn=<AddBackward0>)\n",
      "tensor(23709.2891, grad_fn=<AddBackward0>)\n",
      "tensor(23788.6777, grad_fn=<AddBackward0>)\n",
      "tensor(23807.1016, grad_fn=<AddBackward0>)\n",
      "tensor(23719.4023, grad_fn=<AddBackward0>)\n",
      "tensor(23732.5039, grad_fn=<AddBackward0>)\n",
      "tensor(23762.7969, grad_fn=<AddBackward0>)\n",
      "tensor(23808.8418, grad_fn=<AddBackward0>)\n",
      "tensor(23775.8730, grad_fn=<AddBackward0>)\n",
      "tensor(23810.6211, grad_fn=<AddBackward0>)\n",
      "tensor(23720.8848, grad_fn=<AddBackward0>)\n",
      "tensor(23806.8379, grad_fn=<AddBackward0>)\n",
      "tensor(23732.9961, grad_fn=<AddBackward0>)\n",
      "tensor(23809.7734, grad_fn=<AddBackward0>)\n",
      "tensor(23794.9629, grad_fn=<AddBackward0>)\n",
      "tensor(23724.8066, grad_fn=<AddBackward0>)\n",
      "tensor(23822.0078, grad_fn=<AddBackward0>)\n",
      "tensor(23823.0508, grad_fn=<AddBackward0>)\n",
      "tensor(23824.2734, grad_fn=<AddBackward0>)\n",
      "tensor(23733.6113, grad_fn=<AddBackward0>)\n",
      "tensor(23736.7207, grad_fn=<AddBackward0>)\n",
      "tensor(23787.4199, grad_fn=<AddBackward0>)\n",
      "tensor(23755.9160, grad_fn=<AddBackward0>)\n",
      "tensor(23826.0117, grad_fn=<AddBackward0>)\n",
      "tensor(23771.6172, grad_fn=<AddBackward0>)\n",
      "tensor(23731.5430, grad_fn=<AddBackward0>)\n",
      "tensor(23741.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23820.3613, grad_fn=<AddBackward0>)\n",
      "tensor(23800.2617, grad_fn=<AddBackward0>)\n",
      "tensor(23749.5605, grad_fn=<AddBackward0>)\n",
      "tensor(23831.9922, grad_fn=<AddBackward0>)\n",
      "tensor(23755.4863, grad_fn=<AddBackward0>)\n",
      "tensor(23760.5898, grad_fn=<AddBackward0>)\n",
      "tensor(23755.0820, grad_fn=<AddBackward0>)\n",
      "tensor(23842.4844, grad_fn=<AddBackward0>)\n",
      "tensor(23829.9395, grad_fn=<AddBackward0>)\n",
      "tensor(23754.8516, grad_fn=<AddBackward0>)\n",
      "tensor(23843.1367, grad_fn=<AddBackward0>)\n",
      "tensor(23840.4785, grad_fn=<AddBackward0>)\n",
      "tensor(23742.0391, grad_fn=<AddBackward0>)\n",
      "tensor(23741.1562, grad_fn=<AddBackward0>)\n",
      "tensor(23843.6875, grad_fn=<AddBackward0>)\n",
      "tensor(23756.5605, grad_fn=<AddBackward0>)\n",
      "tensor(23768.8418, grad_fn=<AddBackward0>)\n",
      "tensor(23775.7188, grad_fn=<AddBackward0>)\n",
      "tensor(23839.2852, grad_fn=<AddBackward0>)\n",
      "tensor(23835.2480, grad_fn=<AddBackward0>)\n",
      "tensor(23767.0078, grad_fn=<AddBackward0>)\n",
      "tensor(23832.7812, grad_fn=<AddBackward0>)\n",
      "tensor(23845.5762, grad_fn=<AddBackward0>)\n",
      "tensor(23822.9824, grad_fn=<AddBackward0>)\n",
      "tensor(23831.2461, grad_fn=<AddBackward0>)\n",
      "tensor(23853.8809, grad_fn=<AddBackward0>)\n",
      "tensor(23846.1484, grad_fn=<AddBackward0>)\n",
      "tensor(23763.9082, grad_fn=<AddBackward0>)\n",
      "tensor(23843.7715, grad_fn=<AddBackward0>)\n",
      "tensor(23754.6445, grad_fn=<AddBackward0>)\n",
      "tensor(23794.5703, grad_fn=<AddBackward0>)\n",
      "tensor(23794.7773, grad_fn=<AddBackward0>)\n",
      "tensor(23755.3398, grad_fn=<AddBackward0>)\n",
      "tensor(23785.5332, grad_fn=<AddBackward0>)\n",
      "tensor(23760.0254, grad_fn=<AddBackward0>)\n",
      "tensor(23862.8594, grad_fn=<AddBackward0>)\n",
      "tensor(23768.1680, grad_fn=<AddBackward0>)\n",
      "tensor(23862.7773, grad_fn=<AddBackward0>)\n",
      "tensor(23832.4512, grad_fn=<AddBackward0>)\n",
      "tensor(23824.5293, grad_fn=<AddBackward0>)\n",
      "tensor(23859.9219, grad_fn=<AddBackward0>)\n",
      "tensor(23803.2695, grad_fn=<AddBackward0>)\n",
      "tensor(23853.3535, grad_fn=<AddBackward0>)\n",
      "tensor(23877.2070, grad_fn=<AddBackward0>)\n",
      "tensor(23775.1309, grad_fn=<AddBackward0>)\n",
      "tensor(23866.7285, grad_fn=<AddBackward0>)\n",
      "tensor(23798.4844, grad_fn=<AddBackward0>)\n",
      "tensor(23777.3008, grad_fn=<AddBackward0>)\n",
      "tensor(23879.4355, grad_fn=<AddBackward0>)\n",
      "tensor(23778.7207, grad_fn=<AddBackward0>)\n",
      "tensor(23790.1387, grad_fn=<AddBackward0>)\n",
      "tensor(23808.7676, grad_fn=<AddBackward0>)\n",
      "tensor(23868.9668, grad_fn=<AddBackward0>)\n",
      "tensor(23839.6816, grad_fn=<AddBackward0>)\n",
      "tensor(23880.8281, grad_fn=<AddBackward0>)\n",
      "tensor(23780.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23786.4922, grad_fn=<AddBackward0>)\n",
      "tensor(23858.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23802.4688, grad_fn=<AddBackward0>)\n",
      "tensor(23895.3926, grad_fn=<AddBackward0>)\n",
      "tensor(23786.5723, grad_fn=<AddBackward0>)\n",
      "tensor(23880.9590, grad_fn=<AddBackward0>)\n",
      "tensor(23782.7734, grad_fn=<AddBackward0>)\n",
      "tensor(23878.1953, grad_fn=<AddBackward0>)\n",
      "tensor(23879.9570, grad_fn=<AddBackward0>)\n",
      "tensor(23889.2598, grad_fn=<AddBackward0>)\n",
      "tensor(23859.8652, grad_fn=<AddBackward0>)\n",
      "tensor(23789.0039, grad_fn=<AddBackward0>)\n",
      "tensor(23891.2910, grad_fn=<AddBackward0>)\n",
      "tensor(23796.8535, grad_fn=<AddBackward0>)\n",
      "tensor(23903.0859, grad_fn=<AddBackward0>)\n",
      "tensor(23834.7441, grad_fn=<AddBackward0>)\n",
      "tensor(23790.9277, grad_fn=<AddBackward0>)\n",
      "tensor(23865.1816, grad_fn=<AddBackward0>)\n",
      "tensor(23793.0469, grad_fn=<AddBackward0>)\n",
      "tensor(23801.4297, grad_fn=<AddBackward0>)\n",
      "tensor(23865.6250, grad_fn=<AddBackward0>)\n",
      "tensor(23911.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23794.6289, grad_fn=<AddBackward0>)\n",
      "tensor(23908.5469, grad_fn=<AddBackward0>)\n",
      "tensor(23812.1602, grad_fn=<AddBackward0>)\n",
      "tensor(23815.1777, grad_fn=<AddBackward0>)\n",
      "tensor(23883.9961, grad_fn=<AddBackward0>)\n",
      "tensor(23911.1074, grad_fn=<AddBackward0>)\n",
      "tensor(23904.4043, grad_fn=<AddBackward0>)\n",
      "tensor(23909.2129, grad_fn=<AddBackward0>)\n",
      "tensor(23910.6328, grad_fn=<AddBackward0>)\n",
      "tensor(23908.9961, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23914.5020, grad_fn=<AddBackward0>)\n",
      "tensor(23800.8203, grad_fn=<AddBackward0>)\n",
      "tensor(23880.5176, grad_fn=<AddBackward0>)\n",
      "tensor(23832.5879, grad_fn=<AddBackward0>)\n",
      "tensor(23854.6367, grad_fn=<AddBackward0>)\n",
      "tensor(23907.7188, grad_fn=<AddBackward0>)\n",
      "tensor(23829.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23807.3613, grad_fn=<AddBackward0>)\n",
      "tensor(23872.8848, grad_fn=<AddBackward0>)\n",
      "tensor(23913.8730, grad_fn=<AddBackward0>)\n",
      "tensor(23914.3066, grad_fn=<AddBackward0>)\n",
      "tensor(23819.9336, grad_fn=<AddBackward0>)\n",
      "tensor(23910.4121, grad_fn=<AddBackward0>)\n",
      "tensor(23923.9609, grad_fn=<AddBackward0>)\n",
      "tensor(23912.8555, grad_fn=<AddBackward0>)\n",
      "tensor(23875.7500, grad_fn=<AddBackward0>)\n",
      "tensor(23859.3555, grad_fn=<AddBackward0>)\n",
      "tensor(23816.6621, grad_fn=<AddBackward0>)\n",
      "tensor(23890.7441, grad_fn=<AddBackward0>)\n",
      "tensor(23827.8477, grad_fn=<AddBackward0>)\n",
      "tensor(23865.9277, grad_fn=<AddBackward0>)\n",
      "tensor(23881.6641, grad_fn=<AddBackward0>)\n",
      "tensor(23922.3945, grad_fn=<AddBackward0>)\n",
      "tensor(23901.4824, grad_fn=<AddBackward0>)\n",
      "tensor(23825.4785, grad_fn=<AddBackward0>)\n",
      "tensor(23841.9023, grad_fn=<AddBackward0>)\n",
      "tensor(23927.9121, grad_fn=<AddBackward0>)\n",
      "tensor(23812.1934, grad_fn=<AddBackward0>)\n",
      "tensor(23898.2773, grad_fn=<AddBackward0>)\n",
      "tensor(23930.1445, grad_fn=<AddBackward0>)\n",
      "tensor(23815.9590, grad_fn=<AddBackward0>)\n",
      "tensor(23932.4941, grad_fn=<AddBackward0>)\n",
      "tensor(23866.0742, grad_fn=<AddBackward0>)\n",
      "tensor(23928.5410, grad_fn=<AddBackward0>)\n",
      "tensor(23820.9727, grad_fn=<AddBackward0>)\n",
      "tensor(23837.3770, grad_fn=<AddBackward0>)\n",
      "tensor(23839.4121, grad_fn=<AddBackward0>)\n",
      "tensor(23817.9609, grad_fn=<AddBackward0>)\n",
      "tensor(23814.3320, grad_fn=<AddBackward0>)\n",
      "tensor(23844.6074, grad_fn=<AddBackward0>)\n",
      "tensor(23923.1152, grad_fn=<AddBackward0>)\n",
      "tensor(23935.5977, grad_fn=<AddBackward0>)\n",
      "tensor(23853.8711, grad_fn=<AddBackward0>)\n",
      "tensor(23900.2793, grad_fn=<AddBackward0>)\n",
      "tensor(23857.4824, grad_fn=<AddBackward0>)\n",
      "tensor(23820.0430, grad_fn=<AddBackward0>)\n",
      "tensor(23941.3848, grad_fn=<AddBackward0>)\n",
      "tensor(23836.1367, grad_fn=<AddBackward0>)\n",
      "tensor(23950.7207, grad_fn=<AddBackward0>)\n",
      "tensor(23955.1289, grad_fn=<AddBackward0>)\n",
      "tensor(23831.2305, grad_fn=<AddBackward0>)\n",
      "tensor(23952.7051, grad_fn=<AddBackward0>)\n",
      "tensor(23881.0547, grad_fn=<AddBackward0>)\n",
      "tensor(23891.6973, grad_fn=<AddBackward0>)\n",
      "tensor(23823.8125, grad_fn=<AddBackward0>)\n",
      "tensor(23837.2246, grad_fn=<AddBackward0>)\n",
      "tensor(23831.5547, grad_fn=<AddBackward0>)\n",
      "tensor(23935.0840, grad_fn=<AddBackward0>)\n",
      "tensor(23829.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23946.2012, grad_fn=<AddBackward0>)\n",
      "tensor(23938.8730, grad_fn=<AddBackward0>)\n",
      "tensor(23877.0059, grad_fn=<AddBackward0>)\n",
      "tensor(23834.1582, grad_fn=<AddBackward0>)\n",
      "tensor(23934.2246, grad_fn=<AddBackward0>)\n",
      "tensor(23883.8379, grad_fn=<AddBackward0>)\n",
      "tensor(23957.5684, grad_fn=<AddBackward0>)\n",
      "tensor(23938.9531, grad_fn=<AddBackward0>)\n",
      "tensor(23961.8027, grad_fn=<AddBackward0>)\n",
      "tensor(23937.4219, grad_fn=<AddBackward0>)\n",
      "tensor(23947.3242, grad_fn=<AddBackward0>)\n",
      "tensor(23839.6230, grad_fn=<AddBackward0>)\n",
      "tensor(23957.1445, grad_fn=<AddBackward0>)\n",
      "tensor(23837.2461, grad_fn=<AddBackward0>)\n",
      "tensor(23964.1738, grad_fn=<AddBackward0>)\n",
      "tensor(23917.1777, grad_fn=<AddBackward0>)\n",
      "tensor(23833.2148, grad_fn=<AddBackward0>)\n",
      "tensor(23939.4062, grad_fn=<AddBackward0>)\n",
      "tensor(23837.0781, grad_fn=<AddBackward0>)\n",
      "tensor(23841.0020, grad_fn=<AddBackward0>)\n",
      "tensor(23961.3125, grad_fn=<AddBackward0>)\n",
      "tensor(23837.0918, grad_fn=<AddBackward0>)\n",
      "tensor(23953.8301, grad_fn=<AddBackward0>)\n",
      "tensor(23843.5098, grad_fn=<AddBackward0>)\n",
      "tensor(23965.0312, grad_fn=<AddBackward0>)\n",
      "tensor(23873.3301, grad_fn=<AddBackward0>)\n",
      "tensor(23844.5469, grad_fn=<AddBackward0>)\n",
      "tensor(23933.6426, grad_fn=<AddBackward0>)\n",
      "tensor(23899.0801, grad_fn=<AddBackward0>)\n",
      "tensor(23931.8809, grad_fn=<AddBackward0>)\n",
      "tensor(23970.7656, grad_fn=<AddBackward0>)\n",
      "tensor(23969.4102, grad_fn=<AddBackward0>)\n",
      "tensor(23913.4961, grad_fn=<AddBackward0>)\n",
      "tensor(23973.9375, grad_fn=<AddBackward0>)\n",
      "tensor(23956.0547, grad_fn=<AddBackward0>)\n",
      "tensor(23948.7910, grad_fn=<AddBackward0>)\n",
      "tensor(23890.7227, grad_fn=<AddBackward0>)\n",
      "tensor(23886.8867, grad_fn=<AddBackward0>)\n",
      "tensor(23910.2422, grad_fn=<AddBackward0>)\n",
      "tensor(23860.9082, grad_fn=<AddBackward0>)\n",
      "tensor(23876.2266, grad_fn=<AddBackward0>)\n",
      "tensor(23857.7070, grad_fn=<AddBackward0>)\n",
      "tensor(23951.7832, grad_fn=<AddBackward0>)\n",
      "tensor(23853.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23977.4375, grad_fn=<AddBackward0>)\n",
      "tensor(23866.9355, grad_fn=<AddBackward0>)\n",
      "tensor(23975.5957, grad_fn=<AddBackward0>)\n",
      "tensor(23945.2090, grad_fn=<AddBackward0>)\n",
      "tensor(23965.1016, grad_fn=<AddBackward0>)\n",
      "tensor(23980.6621, grad_fn=<AddBackward0>)\n",
      "tensor(23950.2148, grad_fn=<AddBackward0>)\n",
      "tensor(23972.6309, grad_fn=<AddBackward0>)\n",
      "tensor(23948.0742, grad_fn=<AddBackward0>)\n",
      "tensor(23935.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23959.5957, grad_fn=<AddBackward0>)\n",
      "tensor(23869.2832, grad_fn=<AddBackward0>)\n",
      "tensor(23986.0059, grad_fn=<AddBackward0>)\n",
      "tensor(23855.8301, grad_fn=<AddBackward0>)\n",
      "tensor(23867.2402, grad_fn=<AddBackward0>)\n",
      "tensor(23955.8984, grad_fn=<AddBackward0>)\n",
      "tensor(23981.6660, grad_fn=<AddBackward0>)\n",
      "tensor(23862.4082, grad_fn=<AddBackward0>)\n",
      "tensor(23912.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23857.3984, grad_fn=<AddBackward0>)\n",
      "tensor(23985.8730, grad_fn=<AddBackward0>)\n",
      "tensor(23959.7090, grad_fn=<AddBackward0>)\n",
      "tensor(23906.9375, grad_fn=<AddBackward0>)\n",
      "tensor(23904.2559, grad_fn=<AddBackward0>)\n",
      "tensor(23976.2129, grad_fn=<AddBackward0>)\n",
      "tensor(23901.5449, grad_fn=<AddBackward0>)\n",
      "tensor(23960.6465, grad_fn=<AddBackward0>)\n",
      "tensor(23971.2480, grad_fn=<AddBackward0>)\n",
      "tensor(23902.9590, grad_fn=<AddBackward0>)\n",
      "tensor(23870.0527, grad_fn=<AddBackward0>)\n",
      "tensor(23913.5605, grad_fn=<AddBackward0>)\n",
      "tensor(23867.9980, grad_fn=<AddBackward0>)\n",
      "tensor(23906.8926, grad_fn=<AddBackward0>)\n",
      "tensor(23975.0410, grad_fn=<AddBackward0>)\n",
      "tensor(23858.4512, grad_fn=<AddBackward0>)\n",
      "tensor(23878.4980, grad_fn=<AddBackward0>)\n",
      "tensor(23972.4922, grad_fn=<AddBackward0>)\n",
      "tensor(23859.5117, grad_fn=<AddBackward0>)\n",
      "tensor(23937.3965, grad_fn=<AddBackward0>)\n",
      "tensor(23976.3359, grad_fn=<AddBackward0>)\n",
      "tensor(23879.3848, grad_fn=<AddBackward0>)\n",
      "tensor(23877.8848, grad_fn=<AddBackward0>)\n",
      "tensor(23905.0469, grad_fn=<AddBackward0>)\n",
      "tensor(23897.9570, grad_fn=<AddBackward0>)\n",
      "tensor(23940.7441, grad_fn=<AddBackward0>)\n",
      "tensor(24003., grad_fn=<AddBackward0>)\n",
      "tensor(23941.8613, grad_fn=<AddBackward0>)\n",
      "tensor(23966.2734, grad_fn=<AddBackward0>)\n",
      "tensor(23942.6035, grad_fn=<AddBackward0>)\n",
      "tensor(23873.2812, grad_fn=<AddBackward0>)\n",
      "tensor(23949.6777, grad_fn=<AddBackward0>)\n",
      "tensor(23928.3848, grad_fn=<AddBackward0>)\n",
      "tensor(23870.7070, grad_fn=<AddBackward0>)\n",
      "tensor(23994.6895, grad_fn=<AddBackward0>)\n",
      "tensor(23873.1406, grad_fn=<AddBackward0>)\n",
      "tensor(23863.9473, grad_fn=<AddBackward0>)\n",
      "tensor(23883.3770, grad_fn=<AddBackward0>)\n",
      "tensor(23963.7148, grad_fn=<AddBackward0>)\n",
      "tensor(23906.3887, grad_fn=<AddBackward0>)\n",
      "tensor(23962.2266, grad_fn=<AddBackward0>)\n",
      "tensor(23896.9336, grad_fn=<AddBackward0>)\n",
      "tensor(23876.7148, grad_fn=<AddBackward0>)\n",
      "tensor(23880.6484, grad_fn=<AddBackward0>)\n",
      "tensor(23915.3340, grad_fn=<AddBackward0>)\n",
      "tensor(23936.7500, grad_fn=<AddBackward0>)\n",
      "tensor(23895.2207, grad_fn=<AddBackward0>)\n",
      "tensor(23967.8223, grad_fn=<AddBackward0>)\n",
      "tensor(23884.4648, grad_fn=<AddBackward0>)\n",
      "tensor(23969.4707, grad_fn=<AddBackward0>)\n",
      "tensor(23920.0840, grad_fn=<AddBackward0>)\n",
      "tensor(23947.8828, grad_fn=<AddBackward0>)\n",
      "tensor(23880.1816, grad_fn=<AddBackward0>)\n",
      "tensor(23883.8457, grad_fn=<AddBackward0>)\n",
      "tensor(23955.9121, grad_fn=<AddBackward0>)\n",
      "tensor(23979.7617, grad_fn=<AddBackward0>)\n",
      "tensor(24017.7793, grad_fn=<AddBackward0>)\n",
      "tensor(23900.4082, grad_fn=<AddBackward0>)\n",
      "tensor(23876.6934, grad_fn=<AddBackward0>)\n",
      "tensor(24020.2871, grad_fn=<AddBackward0>)\n",
      "tensor(23981.3945, grad_fn=<AddBackward0>)\n",
      "tensor(23993.5371, grad_fn=<AddBackward0>)\n",
      "tensor(23912.2188, grad_fn=<AddBackward0>)\n",
      "tensor(23911.1680, grad_fn=<AddBackward0>)\n",
      "tensor(23893.3340, grad_fn=<AddBackward0>)\n",
      "tensor(23897.0195, grad_fn=<AddBackward0>)\n",
      "tensor(24019.2090, grad_fn=<AddBackward0>)\n",
      "tensor(24018.7500, grad_fn=<AddBackward0>)\n",
      "tensor(23941.2363, grad_fn=<AddBackward0>)\n",
      "tensor(23952.0176, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23911.8262, grad_fn=<AddBackward0>)\n",
      "tensor(24009.3223, grad_fn=<AddBackward0>)\n",
      "tensor(23926.4141, grad_fn=<AddBackward0>)\n",
      "tensor(23923.4004, grad_fn=<AddBackward0>)\n",
      "tensor(23904.1445, grad_fn=<AddBackward0>)\n",
      "tensor(23889.0254, grad_fn=<AddBackward0>)\n",
      "tensor(23939.8594, grad_fn=<AddBackward0>)\n",
      "tensor(23952.5176, grad_fn=<AddBackward0>)\n",
      "tensor(23930.6660, grad_fn=<AddBackward0>)\n",
      "tensor(24007.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23896.5664, grad_fn=<AddBackward0>)\n",
      "tensor(23881.5371, grad_fn=<AddBackward0>)\n",
      "tensor(23949.4824, grad_fn=<AddBackward0>)\n",
      "tensor(23902.6895, grad_fn=<AddBackward0>)\n",
      "tensor(23916.9492, grad_fn=<AddBackward0>)\n",
      "tensor(23889.7812, grad_fn=<AddBackward0>)\n",
      "tensor(23918.9922, grad_fn=<AddBackward0>)\n",
      "tensor(23982.9531, grad_fn=<AddBackward0>)\n",
      "tensor(23952.1191, grad_fn=<AddBackward0>)\n",
      "tensor(23950.0488, grad_fn=<AddBackward0>)\n",
      "tensor(23893.8145, grad_fn=<AddBackward0>)\n",
      "tensor(24029.4902, grad_fn=<AddBackward0>)\n",
      "tensor(23930.3516, grad_fn=<AddBackward0>)\n",
      "tensor(23999.2793, grad_fn=<AddBackward0>)\n",
      "tensor(23911.6445, grad_fn=<AddBackward0>)\n",
      "tensor(24011.5996, grad_fn=<AddBackward0>)\n",
      "tensor(24026.2637, grad_fn=<AddBackward0>)\n",
      "tensor(23899.7422, grad_fn=<AddBackward0>)\n",
      "tensor(23917.4648, grad_fn=<AddBackward0>)\n",
      "tensor(23988.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23901.3535, grad_fn=<AddBackward0>)\n",
      "tensor(23970.6660, grad_fn=<AddBackward0>)\n",
      "tensor(23924.6621, grad_fn=<AddBackward0>)\n",
      "tensor(24026.8125, grad_fn=<AddBackward0>)\n",
      "tensor(24036.1113, grad_fn=<AddBackward0>)\n",
      "tensor(24026.4277, grad_fn=<AddBackward0>)\n",
      "tensor(23919.6328, grad_fn=<AddBackward0>)\n",
      "tensor(23922.9902, grad_fn=<AddBackward0>)\n",
      "tensor(23902.8457, grad_fn=<AddBackward0>)\n",
      "tensor(24003.3301, grad_fn=<AddBackward0>)\n",
      "tensor(24038.1895, grad_fn=<AddBackward0>)\n",
      "tensor(23992.5312, grad_fn=<AddBackward0>)\n",
      "tensor(23920.6309, grad_fn=<AddBackward0>)\n",
      "tensor(24012.9395, grad_fn=<AddBackward0>)\n",
      "tensor(23911.6504, grad_fn=<AddBackward0>)\n",
      "tensor(23981.7402, grad_fn=<AddBackward0>)\n",
      "tensor(24023.0078, grad_fn=<AddBackward0>)\n",
      "tensor(23964.5137, grad_fn=<AddBackward0>)\n",
      "tensor(23918.9922, grad_fn=<AddBackward0>)\n",
      "tensor(23927.2188, grad_fn=<AddBackward0>)\n",
      "tensor(23900.9121, grad_fn=<AddBackward0>)\n",
      "tensor(24038.0586, grad_fn=<AddBackward0>)\n",
      "tensor(24036.6035, grad_fn=<AddBackward0>)\n",
      "tensor(24045.3262, grad_fn=<AddBackward0>)\n",
      "tensor(24017.6602, grad_fn=<AddBackward0>)\n",
      "tensor(23942.6738, grad_fn=<AddBackward0>)\n",
      "tensor(24029.2227, grad_fn=<AddBackward0>)\n",
      "tensor(23915.6855, grad_fn=<AddBackward0>)\n",
      "tensor(24020.4160, grad_fn=<AddBackward0>)\n",
      "tensor(23991.3594, grad_fn=<AddBackward0>)\n",
      "tensor(23986.4375, grad_fn=<AddBackward0>)\n",
      "tensor(24008.5586, grad_fn=<AddBackward0>)\n",
      "tensor(23980.2793, grad_fn=<AddBackward0>)\n",
      "tensor(24024.2695, grad_fn=<AddBackward0>)\n",
      "tensor(23916.9102, grad_fn=<AddBackward0>)\n",
      "tensor(23999.6094, grad_fn=<AddBackward0>)\n",
      "tensor(24048.1582, grad_fn=<AddBackward0>)\n",
      "tensor(23911.4883, grad_fn=<AddBackward0>)\n",
      "tensor(23899.0391, grad_fn=<AddBackward0>)\n",
      "tensor(23919.1562, grad_fn=<AddBackward0>)\n",
      "tensor(23904.2812, grad_fn=<AddBackward0>)\n",
      "tensor(24023.3809, grad_fn=<AddBackward0>)\n",
      "tensor(23901.8281, grad_fn=<AddBackward0>)\n",
      "tensor(23906.9082, grad_fn=<AddBackward0>)\n",
      "tensor(23952.3184, grad_fn=<AddBackward0>)\n",
      "tensor(24023.8105, grad_fn=<AddBackward0>)\n",
      "tensor(24018.6973, grad_fn=<AddBackward0>)\n",
      "tensor(23905.5898, grad_fn=<AddBackward0>)\n",
      "tensor(23938.0059, grad_fn=<AddBackward0>)\n",
      "tensor(24041.3926, grad_fn=<AddBackward0>)\n",
      "tensor(24009.0020, grad_fn=<AddBackward0>)\n",
      "tensor(23976.3613, grad_fn=<AddBackward0>)\n",
      "tensor(23940.7070, grad_fn=<AddBackward0>)\n",
      "tensor(23980.1953, grad_fn=<AddBackward0>)\n",
      "tensor(24053.6914, grad_fn=<AddBackward0>)\n",
      "tensor(23968.3496, grad_fn=<AddBackward0>)\n",
      "tensor(23914.7324, grad_fn=<AddBackward0>)\n",
      "tensor(24049.3438, grad_fn=<AddBackward0>)\n",
      "tensor(24054.9609, grad_fn=<AddBackward0>)\n",
      "tensor(23917.0039, grad_fn=<AddBackward0>)\n",
      "tensor(23909.5059, grad_fn=<AddBackward0>)\n",
      "tensor(23939.0586, grad_fn=<AddBackward0>)\n",
      "tensor(23916.9883, grad_fn=<AddBackward0>)\n",
      "tensor(23982.5391, grad_fn=<AddBackward0>)\n",
      "tensor(23928.4414, grad_fn=<AddBackward0>)\n",
      "tensor(23948.8594, grad_fn=<AddBackward0>)\n",
      "tensor(23908.2676, grad_fn=<AddBackward0>)\n",
      "tensor(24051.0156, grad_fn=<AddBackward0>)\n",
      "tensor(24051.4336, grad_fn=<AddBackward0>)\n",
      "tensor(24027.2148, grad_fn=<AddBackward0>)\n",
      "tensor(24051.0332, grad_fn=<AddBackward0>)\n",
      "tensor(23917.2832, grad_fn=<AddBackward0>)\n",
      "tensor(23971.0371, grad_fn=<AddBackward0>)\n",
      "tensor(23976.6016, grad_fn=<AddBackward0>)\n",
      "tensor(23914.1074, grad_fn=<AddBackward0>)\n",
      "tensor(24034.7109, grad_fn=<AddBackward0>)\n",
      "tensor(23911.3633, grad_fn=<AddBackward0>)\n",
      "tensor(23931.8242, grad_fn=<AddBackward0>)\n",
      "tensor(23931.1523, grad_fn=<AddBackward0>)\n",
      "tensor(23910.1484, grad_fn=<AddBackward0>)\n",
      "tensor(24065.1367, grad_fn=<AddBackward0>)\n",
      "tensor(24045.5664, grad_fn=<AddBackward0>)\n",
      "tensor(23920.4062, grad_fn=<AddBackward0>)\n",
      "tensor(23959.8008, grad_fn=<AddBackward0>)\n",
      "tensor(24054.5938, grad_fn=<AddBackward0>)\n",
      "tensor(24034.6641, grad_fn=<AddBackward0>)\n",
      "tensor(24067.7656, grad_fn=<AddBackward0>)\n",
      "tensor(24041.2578, grad_fn=<AddBackward0>)\n",
      "tensor(24069.5918, grad_fn=<AddBackward0>)\n",
      "tensor(24062.0020, grad_fn=<AddBackward0>)\n",
      "tensor(24012.4766, grad_fn=<AddBackward0>)\n",
      "tensor(23971.5801, grad_fn=<AddBackward0>)\n",
      "tensor(24068.3242, grad_fn=<AddBackward0>)\n",
      "tensor(23929.5664, grad_fn=<AddBackward0>)\n",
      "tensor(23913.1992, grad_fn=<AddBackward0>)\n",
      "tensor(24054.3789, grad_fn=<AddBackward0>)\n",
      "tensor(24009.7324, grad_fn=<AddBackward0>)\n",
      "tensor(24022.7422, grad_fn=<AddBackward0>)\n",
      "tensor(24063.7402, grad_fn=<AddBackward0>)\n",
      "tensor(24010.1875, grad_fn=<AddBackward0>)\n",
      "tensor(23988.3984, grad_fn=<AddBackward0>)\n",
      "tensor(24054.1562, grad_fn=<AddBackward0>)\n",
      "tensor(23950.5977, grad_fn=<AddBackward0>)\n",
      "tensor(24063.1055, grad_fn=<AddBackward0>)\n",
      "tensor(23924.4336, grad_fn=<AddBackward0>)\n",
      "tensor(23957.4160, grad_fn=<AddBackward0>)\n",
      "tensor(23993.7793, grad_fn=<AddBackward0>)\n",
      "tensor(24071.3320, grad_fn=<AddBackward0>)\n",
      "tensor(24073.7559, grad_fn=<AddBackward0>)\n",
      "tensor(24028.0039, grad_fn=<AddBackward0>)\n",
      "tensor(24043.8750, grad_fn=<AddBackward0>)\n",
      "tensor(23958.7227, grad_fn=<AddBackward0>)\n",
      "tensor(24062.2422, grad_fn=<AddBackward0>)\n",
      "tensor(23918.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23990.9238, grad_fn=<AddBackward0>)\n",
      "tensor(23947.9023, grad_fn=<AddBackward0>)\n",
      "tensor(24022.9395, grad_fn=<AddBackward0>)\n",
      "tensor(23939.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23992.9531, grad_fn=<AddBackward0>)\n",
      "tensor(24026.4336, grad_fn=<AddBackward0>)\n",
      "tensor(24045.7305, grad_fn=<AddBackward0>)\n",
      "tensor(23940.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23922.7617, grad_fn=<AddBackward0>)\n",
      "tensor(24004.4355, grad_fn=<AddBackward0>)\n",
      "tensor(24038.7695, grad_fn=<AddBackward0>)\n",
      "tensor(23993.4434, grad_fn=<AddBackward0>)\n",
      "tensor(23918.5391, grad_fn=<AddBackward0>)\n",
      "tensor(24022.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23989.4688, grad_fn=<AddBackward0>)\n",
      "tensor(23984.9219, grad_fn=<AddBackward0>)\n",
      "tensor(23924.2168, grad_fn=<AddBackward0>)\n",
      "tensor(24052.5898, grad_fn=<AddBackward0>)\n",
      "tensor(23982.5391, grad_fn=<AddBackward0>)\n",
      "tensor(24002.8418, grad_fn=<AddBackward0>)\n",
      "tensor(24030.7832, grad_fn=<AddBackward0>)\n",
      "tensor(24007.0234, grad_fn=<AddBackward0>)\n",
      "tensor(24077.0996, grad_fn=<AddBackward0>)\n",
      "tensor(24038.9316, grad_fn=<AddBackward0>)\n",
      "tensor(23994.3496, grad_fn=<AddBackward0>)\n",
      "tensor(24064.5801, grad_fn=<AddBackward0>)\n",
      "tensor(24064.7402, grad_fn=<AddBackward0>)\n",
      "tensor(23920.5059, grad_fn=<AddBackward0>)\n",
      "tensor(24001.4180, grad_fn=<AddBackward0>)\n",
      "tensor(23933.3555, grad_fn=<AddBackward0>)\n",
      "tensor(23949.2969, grad_fn=<AddBackward0>)\n",
      "tensor(23926.7910, grad_fn=<AddBackward0>)\n",
      "tensor(23952.4219, grad_fn=<AddBackward0>)\n",
      "tensor(24008.8789, grad_fn=<AddBackward0>)\n",
      "tensor(24079.2637, grad_fn=<AddBackward0>)\n",
      "tensor(23988.9668, grad_fn=<AddBackward0>)\n",
      "tensor(23949.1016, grad_fn=<AddBackward0>)\n",
      "tensor(23967.2168, grad_fn=<AddBackward0>)\n",
      "tensor(23919.7598, grad_fn=<AddBackward0>)\n",
      "tensor(23921.8555, grad_fn=<AddBackward0>)\n",
      "tensor(23999.0918, grad_fn=<AddBackward0>)\n",
      "tensor(24090.1758, grad_fn=<AddBackward0>)\n",
      "tensor(23998.1367, grad_fn=<AddBackward0>)\n",
      "tensor(24064.5781, grad_fn=<AddBackward0>)\n",
      "tensor(24040.3125, grad_fn=<AddBackward0>)\n",
      "tensor(23973.9863, grad_fn=<AddBackward0>)\n",
      "tensor(24069.9141, grad_fn=<AddBackward0>)\n",
      "tensor(23962.7188, grad_fn=<AddBackward0>)\n",
      "tensor(24041.7012, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24082.2598, grad_fn=<AddBackward0>)\n",
      "tensor(23990.8633, grad_fn=<AddBackward0>)\n",
      "tensor(23985.9883, grad_fn=<AddBackward0>)\n",
      "tensor(23960.5801, grad_fn=<AddBackward0>)\n",
      "tensor(23946.3906, grad_fn=<AddBackward0>)\n",
      "tensor(24048.9297, grad_fn=<AddBackward0>)\n",
      "tensor(24016.5527, grad_fn=<AddBackward0>)\n",
      "tensor(23975.6562, grad_fn=<AddBackward0>)\n",
      "tensor(23999.8379, grad_fn=<AddBackward0>)\n",
      "tensor(24086.7070, grad_fn=<AddBackward0>)\n",
      "tensor(24029.2891, grad_fn=<AddBackward0>)\n",
      "tensor(24053.8438, grad_fn=<AddBackward0>)\n",
      "tensor(24022.1191, grad_fn=<AddBackward0>)\n",
      "tensor(24050.3633, grad_fn=<AddBackward0>)\n",
      "tensor(23925.1992, grad_fn=<AddBackward0>)\n",
      "tensor(24079.8086, grad_fn=<AddBackward0>)\n",
      "tensor(24055.8281, grad_fn=<AddBackward0>)\n",
      "tensor(23997.8438, grad_fn=<AddBackward0>)\n",
      "tensor(24002.3926, grad_fn=<AddBackward0>)\n",
      "tensor(24028.2109, grad_fn=<AddBackward0>)\n",
      "tensor(23953.5664, grad_fn=<AddBackward0>)\n",
      "tensor(24065.2539, grad_fn=<AddBackward0>)\n",
      "tensor(23928.0859, grad_fn=<AddBackward0>)\n",
      "tensor(24059.1797, grad_fn=<AddBackward0>)\n",
      "tensor(24056.3652, grad_fn=<AddBackward0>)\n",
      "tensor(24000.4219, grad_fn=<AddBackward0>)\n",
      "tensor(23960.2324, grad_fn=<AddBackward0>)\n",
      "tensor(24080.2930, grad_fn=<AddBackward0>)\n",
      "tensor(24043.0312, grad_fn=<AddBackward0>)\n",
      "tensor(23946.1914, grad_fn=<AddBackward0>)\n",
      "tensor(24056.3496, grad_fn=<AddBackward0>)\n",
      "tensor(24041.3320, grad_fn=<AddBackward0>)\n",
      "tensor(23991.5234, grad_fn=<AddBackward0>)\n",
      "tensor(24047.4434, grad_fn=<AddBackward0>)\n",
      "tensor(23968.3125, grad_fn=<AddBackward0>)\n",
      "tensor(24039.4414, grad_fn=<AddBackward0>)\n",
      "tensor(24087.9062, grad_fn=<AddBackward0>)\n",
      "tensor(23958.2285, grad_fn=<AddBackward0>)\n",
      "tensor(24036.3457, grad_fn=<AddBackward0>)\n",
      "tensor(24060.7305, grad_fn=<AddBackward0>)\n",
      "tensor(23967.2422, grad_fn=<AddBackward0>)\n",
      "tensor(23937.7969, grad_fn=<AddBackward0>)\n",
      "tensor(23997.0254, grad_fn=<AddBackward0>)\n",
      "tensor(23942.9297, grad_fn=<AddBackward0>)\n",
      "tensor(23970.4336, grad_fn=<AddBackward0>)\n",
      "tensor(24081.4180, grad_fn=<AddBackward0>)\n",
      "tensor(24073.9512, grad_fn=<AddBackward0>)\n",
      "tensor(23945.9004, grad_fn=<AddBackward0>)\n",
      "tensor(24039.9785, grad_fn=<AddBackward0>)\n",
      "tensor(23986.8887, grad_fn=<AddBackward0>)\n",
      "tensor(24106.4102, grad_fn=<AddBackward0>)\n",
      "tensor(23956.1191, grad_fn=<AddBackward0>)\n",
      "tensor(24084.0977, grad_fn=<AddBackward0>)\n",
      "tensor(24019.3164, grad_fn=<AddBackward0>)\n",
      "tensor(24093.5566, grad_fn=<AddBackward0>)\n",
      "tensor(24099.9570, grad_fn=<AddBackward0>)\n",
      "tensor(23974.0586, grad_fn=<AddBackward0>)\n",
      "tensor(24098.5703, grad_fn=<AddBackward0>)\n",
      "tensor(24093.5098, grad_fn=<AddBackward0>)\n",
      "tensor(24080.6602, grad_fn=<AddBackward0>)\n",
      "tensor(24100.9414, grad_fn=<AddBackward0>)\n",
      "tensor(23950.2070, grad_fn=<AddBackward0>)\n",
      "tensor(24031.2500, grad_fn=<AddBackward0>)\n",
      "tensor(23935.9668, grad_fn=<AddBackward0>)\n",
      "tensor(24062.4277, grad_fn=<AddBackward0>)\n",
      "tensor(24079.1758, grad_fn=<AddBackward0>)\n",
      "tensor(23950.9375, grad_fn=<AddBackward0>)\n",
      "tensor(24051.8379, grad_fn=<AddBackward0>)\n",
      "tensor(23937.6465, grad_fn=<AddBackward0>)\n",
      "tensor(23937.2891, grad_fn=<AddBackward0>)\n",
      "tensor(23951.6484, grad_fn=<AddBackward0>)\n",
      "tensor(24101.7930, grad_fn=<AddBackward0>)\n",
      "tensor(24050.9844, grad_fn=<AddBackward0>)\n",
      "tensor(23936.9141, grad_fn=<AddBackward0>)\n",
      "tensor(24062.9453, grad_fn=<AddBackward0>)\n",
      "tensor(24051.3496, grad_fn=<AddBackward0>)\n",
      "tensor(23939.4844, grad_fn=<AddBackward0>)\n",
      "tensor(23990.4141, grad_fn=<AddBackward0>)\n",
      "tensor(24069.6562, grad_fn=<AddBackward0>)\n",
      "tensor(24076.8301, grad_fn=<AddBackward0>)\n",
      "tensor(24102.9863, grad_fn=<AddBackward0>)\n",
      "tensor(23952.0059, grad_fn=<AddBackward0>)\n",
      "tensor(24035.9434, grad_fn=<AddBackward0>)\n",
      "tensor(24051.7871, grad_fn=<AddBackward0>)\n",
      "tensor(24096.7910, grad_fn=<AddBackward0>)\n",
      "tensor(24113.2598, grad_fn=<AddBackward0>)\n",
      "tensor(24084.4844, grad_fn=<AddBackward0>)\n",
      "tensor(24010.6602, grad_fn=<AddBackward0>)\n",
      "tensor(23949.8438, grad_fn=<AddBackward0>)\n",
      "tensor(23951.4609, grad_fn=<AddBackward0>)\n",
      "tensor(24065.6758, grad_fn=<AddBackward0>)\n",
      "tensor(23997.4746, grad_fn=<AddBackward0>)\n",
      "tensor(24056.5273, grad_fn=<AddBackward0>)\n",
      "tensor(24030.2637, grad_fn=<AddBackward0>)\n",
      "tensor(23976.7246, grad_fn=<AddBackward0>)\n",
      "tensor(23990.9824, grad_fn=<AddBackward0>)\n",
      "tensor(24082.3848, grad_fn=<AddBackward0>)\n",
      "tensor(24082.0957, grad_fn=<AddBackward0>)\n",
      "tensor(23967.4688, grad_fn=<AddBackward0>)\n",
      "tensor(23944.3281, grad_fn=<AddBackward0>)\n",
      "tensor(24108.7500, grad_fn=<AddBackward0>)\n",
      "tensor(24118.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23993.7676, grad_fn=<AddBackward0>)\n",
      "tensor(24108.8359, grad_fn=<AddBackward0>)\n",
      "tensor(24057.4746, grad_fn=<AddBackward0>)\n",
      "tensor(23991.7891, grad_fn=<AddBackward0>)\n",
      "tensor(24084.5215, grad_fn=<AddBackward0>)\n",
      "tensor(24122.4492, grad_fn=<AddBackward0>)\n",
      "tensor(23956.6875, grad_fn=<AddBackward0>)\n",
      "tensor(23975.8301, grad_fn=<AddBackward0>)\n",
      "tensor(24024.2383, grad_fn=<AddBackward0>)\n",
      "tensor(24108.4336, grad_fn=<AddBackward0>)\n",
      "tensor(24118.2773, grad_fn=<AddBackward0>)\n",
      "tensor(24016.9961, grad_fn=<AddBackward0>)\n",
      "tensor(23948.6172, grad_fn=<AddBackward0>)\n",
      "tensor(24089.2051, grad_fn=<AddBackward0>)\n",
      "tensor(23937.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23995.1895, grad_fn=<AddBackward0>)\n",
      "tensor(23975.4141, grad_fn=<AddBackward0>)\n",
      "tensor(23941.4043, grad_fn=<AddBackward0>)\n",
      "tensor(24128.7676, grad_fn=<AddBackward0>)\n",
      "tensor(23996.2793, grad_fn=<AddBackward0>)\n",
      "tensor(24010.3750, grad_fn=<AddBackward0>)\n",
      "tensor(24121.4199, grad_fn=<AddBackward0>)\n",
      "tensor(24120.7578, grad_fn=<AddBackward0>)\n",
      "tensor(23966.0469, grad_fn=<AddBackward0>)\n",
      "tensor(24105.3496, grad_fn=<AddBackward0>)\n",
      "tensor(24048.4785, grad_fn=<AddBackward0>)\n",
      "tensor(23978.6172, grad_fn=<AddBackward0>)\n",
      "tensor(24019.9883, grad_fn=<AddBackward0>)\n",
      "tensor(24040.0176, grad_fn=<AddBackward0>)\n",
      "tensor(24081.2969, grad_fn=<AddBackward0>)\n",
      "tensor(24120.5508, grad_fn=<AddBackward0>)\n",
      "tensor(23963.0352, grad_fn=<AddBackward0>)\n",
      "tensor(24054.9785, grad_fn=<AddBackward0>)\n",
      "tensor(23974.7207, grad_fn=<AddBackward0>)\n",
      "tensor(24077.5430, grad_fn=<AddBackward0>)\n",
      "tensor(24123.6797, grad_fn=<AddBackward0>)\n",
      "tensor(23958.4590, grad_fn=<AddBackward0>)\n",
      "tensor(23961.5703, grad_fn=<AddBackward0>)\n",
      "tensor(23966.5859, grad_fn=<AddBackward0>)\n",
      "tensor(23978.9277, grad_fn=<AddBackward0>)\n",
      "tensor(23975.1914, grad_fn=<AddBackward0>)\n",
      "tensor(24003.9043, grad_fn=<AddBackward0>)\n",
      "tensor(24118.4180, grad_fn=<AddBackward0>)\n",
      "tensor(24075.8320, grad_fn=<AddBackward0>)\n",
      "tensor(23944.1406, grad_fn=<AddBackward0>)\n",
      "tensor(23984.5371, grad_fn=<AddBackward0>)\n",
      "tensor(24121.5098, grad_fn=<AddBackward0>)\n",
      "tensor(24098.3691, grad_fn=<AddBackward0>)\n",
      "tensor(24067.3867, grad_fn=<AddBackward0>)\n",
      "tensor(23951.7441, grad_fn=<AddBackward0>)\n",
      "tensor(23964.3242, grad_fn=<AddBackward0>)\n",
      "tensor(24123.1035, grad_fn=<AddBackward0>)\n",
      "tensor(24073.7930, grad_fn=<AddBackward0>)\n",
      "tensor(24133.6777, grad_fn=<AddBackward0>)\n",
      "tensor(24045.6680, grad_fn=<AddBackward0>)\n",
      "tensor(24121.3066, grad_fn=<AddBackward0>)\n",
      "tensor(24102.6582, grad_fn=<AddBackward0>)\n",
      "tensor(23982.3027, grad_fn=<AddBackward0>)\n",
      "tensor(24117.0176, grad_fn=<AddBackward0>)\n",
      "tensor(23969.2109, grad_fn=<AddBackward0>)\n",
      "tensor(24057.5312, grad_fn=<AddBackward0>)\n",
      "tensor(24076.8242, grad_fn=<AddBackward0>)\n",
      "tensor(24021.1758, grad_fn=<AddBackward0>)\n",
      "tensor(24048.0410, grad_fn=<AddBackward0>)\n",
      "tensor(24017.5488, grad_fn=<AddBackward0>)\n",
      "tensor(24096.2422, grad_fn=<AddBackward0>)\n",
      "tensor(24105.0117, grad_fn=<AddBackward0>)\n",
      "tensor(23977.5195, grad_fn=<AddBackward0>)\n",
      "tensor(23982.7578, grad_fn=<AddBackward0>)\n",
      "tensor(24141.8613, grad_fn=<AddBackward0>)\n",
      "tensor(24095.1660, grad_fn=<AddBackward0>)\n",
      "tensor(24109.4531, grad_fn=<AddBackward0>)\n",
      "tensor(24130.4141, grad_fn=<AddBackward0>)\n",
      "tensor(23962.7676, grad_fn=<AddBackward0>)\n",
      "tensor(23958.0488, grad_fn=<AddBackward0>)\n",
      "tensor(24005.9707, grad_fn=<AddBackward0>)\n",
      "tensor(23970.9629, grad_fn=<AddBackward0>)\n",
      "tensor(24080.8848, grad_fn=<AddBackward0>)\n",
      "tensor(24074.1680, grad_fn=<AddBackward0>)\n",
      "tensor(24120.9336, grad_fn=<AddBackward0>)\n",
      "tensor(23964.0879, grad_fn=<AddBackward0>)\n",
      "tensor(23978.6797, grad_fn=<AddBackward0>)\n",
      "tensor(24059.8398, grad_fn=<AddBackward0>)\n",
      "tensor(24063.4668, grad_fn=<AddBackward0>)\n",
      "tensor(24054.9902, grad_fn=<AddBackward0>)\n",
      "tensor(24152.2852, grad_fn=<AddBackward0>)\n",
      "tensor(23982.2715, grad_fn=<AddBackward0>)\n",
      "tensor(24143.5273, grad_fn=<AddBackward0>)\n",
      "tensor(24118.4199, grad_fn=<AddBackward0>)\n",
      "tensor(23969.2168, grad_fn=<AddBackward0>)\n",
      "tensor(24114.0645, grad_fn=<AddBackward0>)\n",
      "tensor(24029.3359, grad_fn=<AddBackward0>)\n",
      "tensor(24094.0371, grad_fn=<AddBackward0>)\n",
      "tensor(23954.6406, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23955.4902, grad_fn=<AddBackward0>)\n",
      "tensor(23960.1133, grad_fn=<AddBackward0>)\n",
      "tensor(24001.9453, grad_fn=<AddBackward0>)\n",
      "tensor(23977.4355, grad_fn=<AddBackward0>)\n",
      "tensor(24150.3652, grad_fn=<AddBackward0>)\n",
      "tensor(24033.3750, grad_fn=<AddBackward0>)\n",
      "tensor(24096.2227, grad_fn=<AddBackward0>)\n",
      "tensor(23953.1230, grad_fn=<AddBackward0>)\n",
      "tensor(23952.5293, grad_fn=<AddBackward0>)\n",
      "tensor(23990.2305, grad_fn=<AddBackward0>)\n",
      "tensor(24150.0312, grad_fn=<AddBackward0>)\n",
      "tensor(24142.2070, grad_fn=<AddBackward0>)\n",
      "tensor(24069.4375, grad_fn=<AddBackward0>)\n",
      "tensor(24127.6035, grad_fn=<AddBackward0>)\n",
      "tensor(23986.1133, grad_fn=<AddBackward0>)\n",
      "tensor(24069.8672, grad_fn=<AddBackward0>)\n",
      "tensor(24097.3809, grad_fn=<AddBackward0>)\n",
      "tensor(24041.3223, grad_fn=<AddBackward0>)\n",
      "tensor(23980.4980, grad_fn=<AddBackward0>)\n",
      "tensor(24014.3125, grad_fn=<AddBackward0>)\n",
      "tensor(24000.0625, grad_fn=<AddBackward0>)\n",
      "tensor(24161.4434, grad_fn=<AddBackward0>)\n",
      "tensor(24078.4492, grad_fn=<AddBackward0>)\n",
      "tensor(24105.3613, grad_fn=<AddBackward0>)\n",
      "tensor(24161.7461, grad_fn=<AddBackward0>)\n",
      "tensor(23958.3945, grad_fn=<AddBackward0>)\n",
      "tensor(24013.0996, grad_fn=<AddBackward0>)\n",
      "tensor(24014.5762, grad_fn=<AddBackward0>)\n",
      "tensor(24081.2598, grad_fn=<AddBackward0>)\n",
      "tensor(23990.4180, grad_fn=<AddBackward0>)\n",
      "tensor(24067.7188, grad_fn=<AddBackward0>)\n",
      "tensor(24010.9375, grad_fn=<AddBackward0>)\n",
      "tensor(24059.6953, grad_fn=<AddBackward0>)\n",
      "tensor(24015.1445, grad_fn=<AddBackward0>)\n",
      "tensor(24157.2617, grad_fn=<AddBackward0>)\n",
      "tensor(24077.0254, grad_fn=<AddBackward0>)\n",
      "tensor(24075.3613, grad_fn=<AddBackward0>)\n",
      "tensor(24154.2773, grad_fn=<AddBackward0>)\n",
      "tensor(24069.6738, grad_fn=<AddBackward0>)\n",
      "tensor(24156.4629, grad_fn=<AddBackward0>)\n",
      "tensor(24129.1016, grad_fn=<AddBackward0>)\n",
      "tensor(24148.1973, grad_fn=<AddBackward0>)\n",
      "tensor(24169.1523, grad_fn=<AddBackward0>)\n",
      "tensor(23978.1504, grad_fn=<AddBackward0>)\n",
      "tensor(24040.0664, grad_fn=<AddBackward0>)\n",
      "tensor(24159.2480, grad_fn=<AddBackward0>)\n",
      "tensor(24151.8672, grad_fn=<AddBackward0>)\n",
      "tensor(24048.5664, grad_fn=<AddBackward0>)\n",
      "tensor(23981.8750, grad_fn=<AddBackward0>)\n",
      "tensor(24055.9785, grad_fn=<AddBackward0>)\n",
      "tensor(24134.2617, grad_fn=<AddBackward0>)\n",
      "tensor(23987.5215, grad_fn=<AddBackward0>)\n",
      "tensor(24137.8789, grad_fn=<AddBackward0>)\n",
      "tensor(23980.6699, grad_fn=<AddBackward0>)\n",
      "tensor(24045.7910, grad_fn=<AddBackward0>)\n",
      "tensor(24125.0664, grad_fn=<AddBackward0>)\n",
      "tensor(24168.8887, grad_fn=<AddBackward0>)\n",
      "tensor(24111.6719, grad_fn=<AddBackward0>)\n",
      "tensor(23956.4512, grad_fn=<AddBackward0>)\n",
      "tensor(23981.8496, grad_fn=<AddBackward0>)\n",
      "tensor(23965.3066, grad_fn=<AddBackward0>)\n",
      "tensor(24094.3379, grad_fn=<AddBackward0>)\n",
      "tensor(24092.8906, grad_fn=<AddBackward0>)\n",
      "tensor(24105.3750, grad_fn=<AddBackward0>)\n",
      "tensor(24134.1797, grad_fn=<AddBackward0>)\n",
      "tensor(24169.4902, grad_fn=<AddBackward0>)\n",
      "tensor(24148.8496, grad_fn=<AddBackward0>)\n",
      "tensor(24148.3809, grad_fn=<AddBackward0>)\n",
      "tensor(23952.1602, grad_fn=<AddBackward0>)\n",
      "tensor(24058.0645, grad_fn=<AddBackward0>)\n",
      "tensor(24073.7305, grad_fn=<AddBackward0>)\n",
      "tensor(23956.0195, grad_fn=<AddBackward0>)\n",
      "tensor(24142.3047, grad_fn=<AddBackward0>)\n",
      "tensor(24062.3242, grad_fn=<AddBackward0>)\n",
      "tensor(23991.7031, grad_fn=<AddBackward0>)\n",
      "tensor(24092.8984, grad_fn=<AddBackward0>)\n",
      "tensor(24038.6113, grad_fn=<AddBackward0>)\n",
      "tensor(23959.8438, grad_fn=<AddBackward0>)\n",
      "tensor(24124.0996, grad_fn=<AddBackward0>)\n",
      "tensor(23962.3398, grad_fn=<AddBackward0>)\n",
      "tensor(23973.1172, grad_fn=<AddBackward0>)\n",
      "tensor(24122.0723, grad_fn=<AddBackward0>)\n",
      "tensor(24118.9277, grad_fn=<AddBackward0>)\n",
      "tensor(24160.5410, grad_fn=<AddBackward0>)\n",
      "tensor(23967.4961, grad_fn=<AddBackward0>)\n",
      "tensor(24127.0996, grad_fn=<AddBackward0>)\n",
      "tensor(24143.0840, grad_fn=<AddBackward0>)\n",
      "tensor(24175.6406, grad_fn=<AddBackward0>)\n",
      "tensor(24089.9746, grad_fn=<AddBackward0>)\n",
      "tensor(24111.0371, grad_fn=<AddBackward0>)\n",
      "tensor(24134.1641, grad_fn=<AddBackward0>)\n",
      "tensor(24043.8242, grad_fn=<AddBackward0>)\n",
      "tensor(24174.2324, grad_fn=<AddBackward0>)\n",
      "tensor(23979.5645, grad_fn=<AddBackward0>)\n",
      "tensor(24169.1309, grad_fn=<AddBackward0>)\n",
      "tensor(24146.1016, grad_fn=<AddBackward0>)\n",
      "tensor(24005.1211, grad_fn=<AddBackward0>)\n",
      "tensor(24063.5176, grad_fn=<AddBackward0>)\n",
      "tensor(24098.7617, grad_fn=<AddBackward0>)\n",
      "tensor(24066.4668, grad_fn=<AddBackward0>)\n",
      "tensor(24063.2715, grad_fn=<AddBackward0>)\n",
      "tensor(24146.8438, grad_fn=<AddBackward0>)\n",
      "tensor(24176.9023, grad_fn=<AddBackward0>)\n",
      "tensor(23986.1191, grad_fn=<AddBackward0>)\n",
      "tensor(24142.8418, grad_fn=<AddBackward0>)\n",
      "tensor(24155.7578, grad_fn=<AddBackward0>)\n",
      "tensor(24093.4570, grad_fn=<AddBackward0>)\n",
      "tensor(23995.3574, grad_fn=<AddBackward0>)\n",
      "tensor(23974.9922, grad_fn=<AddBackward0>)\n",
      "tensor(24167.4199, grad_fn=<AddBackward0>)\n",
      "tensor(24142.7949, grad_fn=<AddBackward0>)\n",
      "tensor(23986.4668, grad_fn=<AddBackward0>)\n",
      "tensor(23994.8652, grad_fn=<AddBackward0>)\n",
      "tensor(24004.4980, grad_fn=<AddBackward0>)\n",
      "tensor(23950.8809, grad_fn=<AddBackward0>)\n",
      "tensor(24067.2461, grad_fn=<AddBackward0>)\n",
      "tensor(24142.1602, grad_fn=<AddBackward0>)\n",
      "tensor(23950.6621, grad_fn=<AddBackward0>)\n",
      "tensor(24150.6621, grad_fn=<AddBackward0>)\n",
      "tensor(24145.7305, grad_fn=<AddBackward0>)\n",
      "tensor(23988.1758, grad_fn=<AddBackward0>)\n",
      "tensor(24004.7930, grad_fn=<AddBackward0>)\n",
      "tensor(24078.5996, grad_fn=<AddBackward0>)\n",
      "tensor(23983.8594, grad_fn=<AddBackward0>)\n",
      "tensor(23954.4355, grad_fn=<AddBackward0>)\n",
      "tensor(23983.0840, grad_fn=<AddBackward0>)\n",
      "tensor(24131.1992, grad_fn=<AddBackward0>)\n",
      "tensor(24014.2871, grad_fn=<AddBackward0>)\n",
      "tensor(24184.3516, grad_fn=<AddBackward0>)\n",
      "tensor(24130.7871, grad_fn=<AddBackward0>)\n",
      "tensor(24074.4922, grad_fn=<AddBackward0>)\n",
      "tensor(24048.8379, grad_fn=<AddBackward0>)\n",
      "tensor(24087.2539, grad_fn=<AddBackward0>)\n",
      "tensor(23998.7227, grad_fn=<AddBackward0>)\n",
      "tensor(24148.1367, grad_fn=<AddBackward0>)\n",
      "tensor(24092.3242, grad_fn=<AddBackward0>)\n",
      "tensor(24090.2969, grad_fn=<AddBackward0>)\n",
      "tensor(23975.8652, grad_fn=<AddBackward0>)\n",
      "tensor(24139.1738, grad_fn=<AddBackward0>)\n",
      "tensor(24151.2461, grad_fn=<AddBackward0>)\n",
      "tensor(24042.4492, grad_fn=<AddBackward0>)\n",
      "tensor(24156.2578, grad_fn=<AddBackward0>)\n",
      "tensor(24191.0234, grad_fn=<AddBackward0>)\n",
      "tensor(24119.8145, grad_fn=<AddBackward0>)\n",
      "tensor(24195.5039, grad_fn=<AddBackward0>)\n",
      "tensor(24176.0039, grad_fn=<AddBackward0>)\n",
      "tensor(24047.1543, grad_fn=<AddBackward0>)\n",
      "tensor(24186.4941, grad_fn=<AddBackward0>)\n",
      "tensor(24112.6504, grad_fn=<AddBackward0>)\n",
      "tensor(23991.3574, grad_fn=<AddBackward0>)\n",
      "tensor(23994.8535, grad_fn=<AddBackward0>)\n",
      "tensor(24103., grad_fn=<AddBackward0>)\n",
      "tensor(24153.6836, grad_fn=<AddBackward0>)\n",
      "tensor(23990.1973, grad_fn=<AddBackward0>)\n",
      "tensor(23979.4727, grad_fn=<AddBackward0>)\n",
      "tensor(23968.4121, grad_fn=<AddBackward0>)\n",
      "tensor(23967.9824, grad_fn=<AddBackward0>)\n",
      "tensor(24200.9668, grad_fn=<AddBackward0>)\n",
      "tensor(24122.8203, grad_fn=<AddBackward0>)\n",
      "tensor(24045.2402, grad_fn=<AddBackward0>)\n",
      "tensor(23963.7793, grad_fn=<AddBackward0>)\n",
      "tensor(24092.4570, grad_fn=<AddBackward0>)\n",
      "tensor(24073.4961, grad_fn=<AddBackward0>)\n",
      "tensor(24014.5215, grad_fn=<AddBackward0>)\n",
      "tensor(24014.9453, grad_fn=<AddBackward0>)\n",
      "tensor(24075.1387, grad_fn=<AddBackward0>)\n",
      "tensor(24101.7910, grad_fn=<AddBackward0>)\n",
      "tensor(23991.6133, grad_fn=<AddBackward0>)\n",
      "tensor(23976.8770, grad_fn=<AddBackward0>)\n",
      "tensor(24022.8223, grad_fn=<AddBackward0>)\n",
      "tensor(24192.6289, grad_fn=<AddBackward0>)\n",
      "tensor(23970.4199, grad_fn=<AddBackward0>)\n",
      "tensor(24006.4609, grad_fn=<AddBackward0>)\n",
      "tensor(24136.9922, grad_fn=<AddBackward0>)\n",
      "tensor(23996.5273, grad_fn=<AddBackward0>)\n",
      "tensor(24084.8418, grad_fn=<AddBackward0>)\n",
      "tensor(24168.1875, grad_fn=<AddBackward0>)\n",
      "tensor(24061.5312, grad_fn=<AddBackward0>)\n",
      "tensor(24136.6328, grad_fn=<AddBackward0>)\n",
      "tensor(23995.8418, grad_fn=<AddBackward0>)\n",
      "tensor(23994.3320, grad_fn=<AddBackward0>)\n",
      "tensor(24202.6055, grad_fn=<AddBackward0>)\n",
      "tensor(24154.7988, grad_fn=<AddBackward0>)\n",
      "tensor(24147.1855, grad_fn=<AddBackward0>)\n",
      "tensor(23967.1406, grad_fn=<AddBackward0>)\n",
      "tensor(23992.1426, grad_fn=<AddBackward0>)\n",
      "tensor(24001.1250, grad_fn=<AddBackward0>)\n",
      "tensor(24143.6016, grad_fn=<AddBackward0>)\n",
      "tensor(23981.4395, grad_fn=<AddBackward0>)\n",
      "tensor(24177.6816, grad_fn=<AddBackward0>)\n",
      "tensor(23997.5508, grad_fn=<AddBackward0>)\n",
      "tensor(23988.3125, grad_fn=<AddBackward0>)\n",
      "tensor(24210.4668, grad_fn=<AddBackward0>)\n",
      "tensor(24181.5625, grad_fn=<AddBackward0>)\n",
      "tensor(23996.3789, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24193.9863, grad_fn=<AddBackward0>)\n",
      "tensor(24007.8828, grad_fn=<AddBackward0>)\n",
      "tensor(24165.4160, grad_fn=<AddBackward0>)\n",
      "tensor(23984.4102, grad_fn=<AddBackward0>)\n",
      "tensor(23954.4883, grad_fn=<AddBackward0>)\n",
      "tensor(24192.7812, grad_fn=<AddBackward0>)\n",
      "tensor(23996.6465, grad_fn=<AddBackward0>)\n",
      "tensor(24199.8848, grad_fn=<AddBackward0>)\n",
      "tensor(24008.8984, grad_fn=<AddBackward0>)\n",
      "tensor(24154.1191, grad_fn=<AddBackward0>)\n",
      "tensor(24176.5410, grad_fn=<AddBackward0>)\n",
      "tensor(24169.6895, grad_fn=<AddBackward0>)\n",
      "tensor(24097.5215, grad_fn=<AddBackward0>)\n",
      "tensor(24003.3164, grad_fn=<AddBackward0>)\n",
      "tensor(24195.5078, grad_fn=<AddBackward0>)\n",
      "tensor(24060.3574, grad_fn=<AddBackward0>)\n",
      "tensor(24110.7129, grad_fn=<AddBackward0>)\n",
      "tensor(23983.1875, grad_fn=<AddBackward0>)\n",
      "tensor(23981.8301, grad_fn=<AddBackward0>)\n",
      "tensor(24194.2266, grad_fn=<AddBackward0>)\n",
      "tensor(24100.0781, grad_fn=<AddBackward0>)\n",
      "tensor(24152.6953, grad_fn=<AddBackward0>)\n",
      "tensor(24039.8477, grad_fn=<AddBackward0>)\n",
      "tensor(23954.3027, grad_fn=<AddBackward0>)\n",
      "tensor(24057.9707, grad_fn=<AddBackward0>)\n",
      "tensor(24145.3262, grad_fn=<AddBackward0>)\n",
      "tensor(23973.8438, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#initial = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\n",
    "\n",
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 2.1)]\n",
    "\n",
    "#initial = torch.rand (15, 2)\n",
    "\n",
    "#initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.5)]\n",
    "\n",
    "points = torch.tensor(initial, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([points], lr = 0.001)\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "\n",
    "for _ in range (1000):\n",
    "    L = calc_L (points, simplices)\n",
    "    A = calc_A (simplices, L, len (points))\n",
    "    W = calc_W (E, E_b, A, L, simplices)\n",
    "    pen = rho (points, L, E_b, simplices)\n",
    "    \n",
    "    current_eigen = find_eigenvalues(W, A)\n",
    "    \n",
    "    #loss =   weighted_norm(current_eigen, mu)+pen# calculate loss\n",
    "    loss =   weighted_norm(current_eigen, mu)+pen# calculate loss\n",
    "    #print (mu)\n",
    "    optimizer.zero_grad()  # clear previous gradients\n",
    "    loss.backward()        # compute gradients of all variables wrt loss\n",
    "\n",
    "    optimizer.step()\n",
    "    #print (current_eigen)\n",
    "    print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
