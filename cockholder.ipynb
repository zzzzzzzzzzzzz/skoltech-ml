{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_gram_schmidt_qr(A): # 5 pts\n",
    "    assert A.shape[0] >= A.shape[1], 'm is not >= n'\n",
    "    new_vectors = torch.zeros(A.shape)\n",
    "    for i in range(A.shape[1]):\n",
    "        new_vectors[:,i] += A[:,i]\n",
    "        if i > 0:\n",
    "            tmp = torch.tensor(new_vectors[:,0])\n",
    "            new_vectors[:,i] -= ((A[:,i] @ tmp)/(tmp @ tmp)) * tmp\n",
    "        \n",
    "        for j in range(1,i):\n",
    "            tmp1 = torch.tensor(new_vectors[:,i])\n",
    "            tmp2 = torch.tensor(new_vectors[:,j])\n",
    "            new_vectors[:,i] -= ((tmp1 @ tmp2)/(tmp2 @ tmp2)) * tmp2\n",
    "        \n",
    "    # normalization\n",
    "    for i in range(new_vectors.shape[1]):\n",
    "        tmp3 = torch.tensor(new_vectors[:,i])\n",
    "        new_vectors[:,i] /= torch.tensor(tmp3).norm()\n",
    "    Q = new_vectors\n",
    "    R = torch.zeros((A.shape[1],A.shape[1]))\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(i, A.shape[1]):\n",
    "            R[i,j] += A[:,j] @ new_vectors[:,i]\n",
    "    return -Q, -R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]], requires_grad=True)\n",
    "A1 = torch.tensor([[3., -4, 5], [2, 150, -58], [-4, 24, -31]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1, r1 = torch.qr(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "q2, r2 = modified_gram_schmidt_qr(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8571,  0.3943,  0.3314],\n",
       "        [-0.4286, -0.9029, -0.0343],\n",
       "        [ 0.2857, -0.1714,  0.9429]], grad_fn=<QrBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8571,  0.3943,  0.3314],\n",
       "        [-0.4286, -0.9029, -0.0343],\n",
       "        [ 0.2857, -0.1714,  0.9429]], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -14.0000,  -21.0000,   14.0000],\n",
       "        [   0.0000, -175.0000,   70.0000],\n",
       "        [   0.0000,    0.0000,  -35.0000]], grad_fn=<QrBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -14.0000,  -21.0000,   14.0000],\n",
       "        [  -0.0000, -175.0000,   70.0000],\n",
       "        [  -0.0000,   -0.0000,  -35.0000]], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(q2 @ r2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1429,  1.0064,  1.8583],\n",
       "        [ 9.4286,  2.0272,  4.4091],\n",
       "        [-0.2857,  0.3648,  3.4526]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qralgo(a):\n",
    "    while torch.sqrt(torch.sum(a.tril(-1)-1)) > 1e-9: \n",
    "        q,r = modified_gram_schmidt_qr(a) \n",
    "        a = r @ q\n",
    "    return a\n",
    "\n",
    "def eigvals(a):\n",
    "    return qralgo(a).diag()\n",
    "\n",
    "def weighted_norm(a, b):\n",
    "    norm = 0.0\n",
    "    \n",
    "    for i in range (len (a)):\n",
    "        norm += (a [i] - b [i])**2 / (i + 1)\n",
    "    \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([156.1257, -32.5522,  14.4264], grad_fn=<DiagBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([143.9456, -24.3240,   2.3782])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/dmitriy/MyEnv/other/skoltech/ml/env/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([143.9456, -24.3240,   2.3782])\n",
      "tensor([156.1257, -32.5522,  14.4264], grad_fn=<DiagBackward>)\n",
      "tensor([155.9595, -33.9232,  14.6338], grad_fn=<DiagBackward>)\n",
      "tensor([154.4713, -14.3851,  -6.0560], grad_fn=<DiagBackward>)\n",
      "tensor([  6.0706, 149.3880, -21.3504], grad_fn=<DiagBackward>)\n",
      "tensor([  9.1313, 148.5795, -22.1176], grad_fn=<DiagBackward>)\n",
      "tensor([ 11.6189, 148.7974, -23.1234], grad_fn=<DiagBackward>)\n",
      "tensor([ 13.9154, 148.9776, -23.8424], grad_fn=<DiagBackward>)\n",
      "tensor([ 16.1161, 149.0553, -24.3382], grad_fn=<DiagBackward>)\n",
      "tensor([ 18.2628, 149.0412, -24.6781], grad_fn=<DiagBackward>)\n",
      "tensor([ 20.3768, 148.9494, -24.9066], grad_fn=<DiagBackward>)\n",
      "tensor([ 22.4691, 148.7921, -25.0530], grad_fn=<DiagBackward>)\n",
      "tensor([ 24.5457, 148.5785, -25.1371], grad_fn=<DiagBackward>)\n",
      "tensor([ 26.6093, 148.3160, -25.1724], grad_fn=<DiagBackward>)\n",
      "tensor([ 28.6612, 148.0107, -25.1686], grad_fn=<DiagBackward>)\n",
      "tensor([ 30.7019, 147.6671, -25.1329], grad_fn=<DiagBackward>)\n",
      "tensor([ 32.7313, 147.2892, -25.0707], grad_fn=<DiagBackward>)\n",
      "tensor([ 34.7491, 146.8799, -24.9859], grad_fn=<DiagBackward>)\n",
      "tensor([ 36.7547, 146.4419, -24.8816], grad_fn=<DiagBackward>)\n",
      "tensor([ 38.7477, 145.9774, -24.7605], grad_fn=<DiagBackward>)\n",
      "tensor([ 40.7274, 145.4883, -24.6245], grad_fn=<DiagBackward>)\n",
      "tensor([ 42.6934, 144.9760, -24.4752], grad_fn=<DiagBackward>)\n",
      "tensor([ 44.6451, 144.4421, -24.3142], grad_fn=<DiagBackward>)\n",
      "tensor([ 46.5820, 143.8876, -24.1424], grad_fn=<DiagBackward>)\n",
      "tensor([ 48.5035, 143.3138, -23.9610], grad_fn=<DiagBackward>)\n",
      "tensor([ 50.4094, 142.7215, -23.7706], grad_fn=<DiagBackward>)\n",
      "tensor([ 52.2991, 142.1117, -23.5723], grad_fn=<DiagBackward>)\n",
      "tensor([ 54.1722, 141.4851, -23.3664], grad_fn=<DiagBackward>)\n",
      "tensor([ 56.0285, 140.8424, -23.1537], grad_fn=<DiagBackward>)\n",
      "tensor([ 57.8675, 140.1844, -22.9346], grad_fn=<DiagBackward>)\n",
      "tensor([ 59.6889, 139.5117, -22.7096], grad_fn=<DiagBackward>)\n",
      "tensor([ 61.4924, 138.8246, -22.4791], grad_fn=<DiagBackward>)\n",
      "tensor([ 63.2778, 138.1239, -22.2436], grad_fn=<DiagBackward>)\n",
      "tensor([ 65.0448, 137.4101, -22.0033], grad_fn=<DiagBackward>)\n",
      "tensor([ 66.7932, 136.6837, -21.7586], grad_fn=<DiagBackward>)\n",
      "tensor([ 68.5227, 135.9450, -21.5098], grad_fn=<DiagBackward>)\n",
      "tensor([ 70.2330, 135.1946, -21.2572], grad_fn=<DiagBackward>)\n",
      "tensor([ 71.9241, 134.4328, -21.0010], grad_fn=<DiagBackward>)\n",
      "tensor([ 73.5956, 133.6599, -20.7415], grad_fn=<DiagBackward>)\n",
      "tensor([ 75.2475, 132.8764, -20.4789], grad_fn=<DiagBackward>)\n",
      "tensor([ 76.8795, 132.0827, -20.2135], grad_fn=<DiagBackward>)\n",
      "tensor([ 78.4914, 131.2790, -19.9454], grad_fn=<DiagBackward>)\n",
      "tensor([ 80.0832, 130.4657, -19.6748], grad_fn=<DiagBackward>)\n",
      "tensor([ 81.6547, 129.6431, -19.4020], grad_fn=<DiagBackward>)\n",
      "tensor([ 83.2057, 128.8115, -19.1270], grad_fn=<DiagBackward>)\n",
      "tensor([ 84.7360, 127.9711, -18.8500], grad_fn=<DiagBackward>)\n",
      "tensor([ 86.2457, 127.1224, -18.5713], grad_fn=<DiagBackward>)\n",
      "tensor([ 87.7344, 126.2655, -18.2909], grad_fn=<DiagBackward>)\n",
      "tensor([ 89.2023, 125.4007, -18.0090], grad_fn=<DiagBackward>)\n",
      "tensor([ 90.6490, 124.5283, -17.7257], grad_fn=<DiagBackward>)\n",
      "tensor([ 92.0746, 123.6485, -17.4411], grad_fn=<DiagBackward>)\n",
      "tensor([ 93.4789, 122.7616, -17.1554], grad_fn=<DiagBackward>)\n",
      "tensor([ 94.8619, 121.8677, -16.8687], grad_fn=<DiagBackward>)\n",
      "tensor([ 96.2235, 120.9672, -16.5810], grad_fn=<DiagBackward>)\n",
      "tensor([ 97.5636, 120.0602, -16.2925], grad_fn=<DiagBackward>)\n",
      "tensor([ 98.8821, 119.1469, -16.0034], grad_fn=<DiagBackward>)\n",
      "tensor([100.1789, 118.2277, -15.7135], grad_fn=<DiagBackward>)\n",
      "tensor([101.4542, 117.3026, -15.4231], grad_fn=<DiagBackward>)\n",
      "tensor([102.7077, 116.3719, -15.1323], grad_fn=<DiagBackward>)\n",
      "tensor([103.9394, 115.4357, -14.8411], grad_fn=<DiagBackward>)\n",
      "tensor([105.1494, 114.4943, -14.5495], grad_fn=<DiagBackward>)\n",
      "tensor([106.3375, 113.5478, -14.2577], grad_fn=<DiagBackward>)\n",
      "tensor([107.5038, 112.5965, -13.9658], grad_fn=<DiagBackward>)\n",
      "tensor([108.6482, 111.6405, -13.6737], grad_fn=<DiagBackward>)\n",
      "tensor([109.7709, 110.6801, -13.3816], grad_fn=<DiagBackward>)\n",
      "tensor([110.8716, 109.7152, -13.0895], grad_fn=<DiagBackward>)\n",
      "tensor([111.9505, 108.7463, -12.7974], grad_fn=<DiagBackward>)\n",
      "tensor([113.0077, 107.7733, -12.5055], grad_fn=<DiagBackward>)\n",
      "tensor([114.0430, 106.7966, -12.2137], grad_fn=<DiagBackward>)\n",
      "tensor([115.0566, 105.8162, -11.9221], grad_fn=<DiagBackward>)\n",
      "tensor([116.0485, 104.8324, -11.6307], grad_fn=<DiagBackward>)\n",
      "tensor([117.0188, 103.8452, -11.3397], grad_fn=<DiagBackward>)\n",
      "tensor([117.9674, 102.8549, -11.0489], grad_fn=<DiagBackward>)\n",
      "tensor([118.8946, 101.8617, -10.7586], grad_fn=<DiagBackward>)\n",
      "tensor([119.8004, 100.8657, -10.4688], grad_fn=<DiagBackward>)\n",
      "tensor([120.6848,  99.8670, -10.1793], grad_fn=<DiagBackward>)\n",
      "tensor([121.5480,  98.8660,  -9.8904], grad_fn=<DiagBackward>)\n",
      "tensor([122.3900,  97.8626,  -9.6020], grad_fn=<DiagBackward>)\n",
      "tensor([123.2111,  96.8571,  -9.3142], grad_fn=<DiagBackward>)\n",
      "tensor([124.0113,  95.8498,  -9.0271], grad_fn=<DiagBackward>)\n",
      "tensor([124.7908,  94.8407,  -8.7406], grad_fn=<DiagBackward>)\n",
      "tensor([125.5497,  93.8301,  -8.4548], grad_fn=<DiagBackward>)\n",
      "tensor([126.2881,  92.8181,  -8.1699], grad_fn=<DiagBackward>)\n",
      "tensor([127.0064,  91.8051,  -7.8858], grad_fn=<DiagBackward>)\n",
      "tensor([127.7045,  90.7911,  -7.6026], grad_fn=<DiagBackward>)\n",
      "tensor([128.3828,  89.7765,  -7.3202], grad_fn=<DiagBackward>)\n",
      "tensor([129.0414,  88.7614,  -7.0390], grad_fn=<DiagBackward>)\n",
      "tensor([129.6804,  87.7461,  -6.7589], grad_fn=<DiagBackward>)\n",
      "tensor([130.3002,  86.7309,  -6.4799], grad_fn=<DiagBackward>)\n",
      "tensor([130.9009,  85.7161,  -6.2024], grad_fn=<DiagBackward>)\n",
      "tensor([131.4829,  84.7019,  -5.9260], grad_fn=<DiagBackward>)\n",
      "tensor([132.0464,  83.6887,  -5.6512], grad_fn=<DiagBackward>)\n",
      "tensor([132.5915,  82.6769,  -5.3780], grad_fn=<DiagBackward>)\n",
      "tensor([133.1186,  81.6668,  -5.1065], grad_fn=<DiagBackward>)\n",
      "tensor([133.6280,  80.6588,  -4.8369], grad_fn=<DiagBackward>)\n",
      "tensor([134.1198,  79.6535,  -4.5695], grad_fn=<DiagBackward>)\n",
      "tensor([134.5945,  78.6513,  -4.3043], grad_fn=<DiagBackward>)\n",
      "tensor([135.0523,  77.6529,  -4.0416], grad_fn=<DiagBackward>)\n",
      "tensor([135.4935,  76.6589,  -3.7818], grad_fn=<DiagBackward>)\n",
      "tensor([135.9184,  75.6701,  -3.5251], grad_fn=<DiagBackward>)\n",
      "tensor([136.3273,  74.6873,  -3.2717], grad_fn=<DiagBackward>)\n",
      "tensor([136.7206,  73.7117,  -3.0222], grad_fn=<DiagBackward>)\n",
      "tensor([137.0985,  72.7444,  -2.7770], grad_fn=<DiagBackward>)\n",
      "tensor([137.4615,  71.7869,  -2.5373], grad_fn=<DiagBackward>)\n",
      "tensor([137.8098,  70.8409,  -2.3026], grad_fn=<DiagBackward>)\n",
      "tensor([138.1438,  69.9085,  -2.0748], grad_fn=<DiagBackward>)\n",
      "tensor([138.4637,  68.9924,  -1.8545], grad_fn=<DiagBackward>)\n",
      "tensor([138.7701,  68.0958,  -1.6432], grad_fn=<DiagBackward>)\n",
      "tensor([139.0632,  67.2227,  -1.4422], grad_fn=<DiagBackward>)\n",
      "tensor([139.3434,  66.3783,  -1.2536], grad_fn=<DiagBackward>)\n",
      "tensor([139.6110,  65.5687,  -1.0808], grad_fn=<DiagBackward>)\n",
      "tensor([139.8664,  64.8016,  -0.9249], grad_fn=<DiagBackward>)\n",
      "tensor([140.1100,  64.0854,  -0.7903], grad_fn=<DiagBackward>)\n",
      "tensor([140.3420,  63.4282,  -0.6809], grad_fn=<DiagBackward>)\n",
      "tensor([140.5629,  62.8352,  -0.6000], grad_fn=<DiagBackward>)\n",
      "tensor([140.7730,  62.3044,  -0.5465], grad_fn=<DiagBackward>)\n",
      "tensor([140.9726,  61.8240,  -0.5211], grad_fn=<DiagBackward>)\n",
      "tensor([141.1622,  61.3743,  -0.5185], grad_fn=<DiagBackward>)\n",
      "tensor([141.3421,  60.9340,  -0.5331], grad_fn=<DiagBackward>)\n",
      "tensor([141.5125,  60.4861,  -0.5609], grad_fn=<DiagBackward>)\n",
      "tensor([141.6739,  60.0202,  -0.5955], grad_fn=<DiagBackward>)\n",
      "tensor([141.8265,  59.5315,  -0.6358], grad_fn=<DiagBackward>)\n",
      "tensor([141.9707,  59.0183,  -0.6783], grad_fn=<DiagBackward>)\n",
      "tensor([142.1069,  58.4812,  -0.7224], grad_fn=<DiagBackward>)\n",
      "tensor([142.2354,  57.9215,  -0.7657], grad_fn=<DiagBackward>)\n",
      "tensor([142.3565,  57.3410,  -0.8077], grad_fn=<DiagBackward>)\n",
      "tensor([142.4705,  56.7414,  -0.8477], grad_fn=<DiagBackward>)\n",
      "tensor([142.5776,  56.1244,  -0.8844], grad_fn=<DiagBackward>)\n",
      "tensor([142.6783,  55.4917,  -0.9179], grad_fn=<DiagBackward>)\n",
      "tensor([142.7728,  54.8447,  -0.9472], grad_fn=<DiagBackward>)\n",
      "tensor([142.8614,  54.1849,  -0.9729], grad_fn=<DiagBackward>)\n",
      "tensor([142.9444,  53.5136,  -0.9941], grad_fn=<DiagBackward>)\n",
      "tensor([143.0221,  52.8321,  -1.0106], grad_fn=<DiagBackward>)\n",
      "tensor([143.0946,  52.1417,  -1.0232], grad_fn=<DiagBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([143.1623,  51.4435,  -1.0312], grad_fn=<DiagBackward>)\n",
      "tensor([143.2254,  50.7386,  -1.0352], grad_fn=<DiagBackward>)\n",
      "tensor([143.2843,  50.0283,  -1.0352], grad_fn=<DiagBackward>)\n",
      "tensor([143.3390,  49.3137,  -1.0312], grad_fn=<DiagBackward>)\n",
      "tensor([143.3898,  48.5959,  -1.0242], grad_fn=<DiagBackward>)\n",
      "tensor([143.4370,  47.8759,  -1.0142], grad_fn=<DiagBackward>)\n",
      "tensor([143.4808,  47.1549,  -1.0016], grad_fn=<DiagBackward>)\n",
      "tensor([143.5212,  46.4338,  -0.9867], grad_fn=<DiagBackward>)\n",
      "tensor([143.5587,  45.7137,  -0.9704], grad_fn=<DiagBackward>)\n",
      "tensor([143.5933,  44.9954,  -0.9527], grad_fn=<DiagBackward>)\n",
      "tensor([143.6252,  44.2797,  -0.9345], grad_fn=<DiagBackward>)\n",
      "tensor([143.6546,  43.5674,  -0.9158], grad_fn=<DiagBackward>)\n",
      "tensor([143.6817,  42.8590,  -0.8974], grad_fn=<DiagBackward>)\n",
      "tensor([143.7066,  42.1548,  -0.8794], grad_fn=<DiagBackward>)\n",
      "tensor([143.7294,  41.4553,  -0.8624], grad_fn=<DiagBackward>)\n",
      "tensor([143.7503,  40.7604,  -0.8468], grad_fn=<DiagBackward>)\n",
      "tensor([143.7695,  40.0702,  -0.8322], grad_fn=<DiagBackward>)\n",
      "tensor([143.7869,  39.3843,  -0.8194], grad_fn=<DiagBackward>)\n",
      "tensor([143.8029,  38.7023,  -0.8079], grad_fn=<DiagBackward>)\n",
      "tensor([143.8174,  38.0238,  -0.7980], grad_fn=<DiagBackward>)\n",
      "tensor([143.8307,  37.3483,  -0.7893], grad_fn=<DiagBackward>)\n",
      "tensor([143.8427,  36.6753,  -0.7819], grad_fn=<DiagBackward>)\n",
      "tensor([143.8537,  36.0040,  -0.7754], grad_fn=<DiagBackward>)\n",
      "tensor([143.8635,  35.3341,  -0.7695], grad_fn=<DiagBackward>)\n",
      "tensor([143.8725,  34.6650,  -0.7642], grad_fn=<DiagBackward>)\n",
      "tensor([143.8806,  33.9965,  -0.7590], grad_fn=<DiagBackward>)\n",
      "tensor([143.8879,  33.3281,  -0.7538], grad_fn=<DiagBackward>)\n",
      "tensor([143.8944,  32.6599,  -0.7484], grad_fn=<DiagBackward>)\n",
      "tensor([143.9003,  31.9918,  -0.7427], grad_fn=<DiagBackward>)\n",
      "tensor([143.9056,  31.3238,  -0.7362], grad_fn=<DiagBackward>)\n",
      "tensor([143.9104,  30.6560,  -0.7290], grad_fn=<DiagBackward>)\n",
      "tensor([143.9146,  29.9888,  -0.7212], grad_fn=<DiagBackward>)\n",
      "tensor([143.9184,  29.3222,  -0.7127], grad_fn=<DiagBackward>)\n",
      "tensor([143.9218,  28.6568,  -0.7034], grad_fn=<DiagBackward>)\n",
      "tensor([143.9248,  27.9927,  -0.6934], grad_fn=<DiagBackward>)\n",
      "tensor([143.9275,  27.3303,  -0.6830], grad_fn=<DiagBackward>)\n",
      "tensor([143.9298,  26.6699,  -0.6719], grad_fn=<DiagBackward>)\n",
      "tensor([143.9319,  26.0118,  -0.6607], grad_fn=<DiagBackward>)\n",
      "tensor([143.9337,  25.3562,  -0.6491], grad_fn=<DiagBackward>)\n",
      "tensor([143.9353,  24.7032,  -0.6375], grad_fn=<DiagBackward>)\n",
      "tensor([143.9368,  24.0529,  -0.6257], grad_fn=<DiagBackward>)\n",
      "tensor([143.9380,  23.4055,  -0.6140], grad_fn=<DiagBackward>)\n",
      "tensor([143.9392,  22.7608,  -0.6023], grad_fn=<DiagBackward>)\n",
      "tensor([143.9401,  22.1188,  -0.5906], grad_fn=<DiagBackward>)\n",
      "tensor([143.9409,  21.4795,  -0.5789], grad_fn=<DiagBackward>)\n",
      "tensor([143.9417,  20.8428,  -0.5672], grad_fn=<DiagBackward>)\n",
      "tensor([143.9423,  20.2085,  -0.5553], grad_fn=<DiagBackward>)\n",
      "tensor([143.9427,  19.5767,  -0.5434], grad_fn=<DiagBackward>)\n",
      "tensor([143.9432,  18.9472,  -0.5312], grad_fn=<DiagBackward>)\n",
      "tensor([143.9436,  18.3200,  -0.5187], grad_fn=<DiagBackward>)\n",
      "tensor([143.9441,  17.6952,  -0.5059], grad_fn=<DiagBackward>)\n",
      "tensor([143.9445,  17.0728,  -0.4928], grad_fn=<DiagBackward>)\n",
      "tensor([143.9446,  16.4529,  -0.4795], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447,  15.8356,  -0.4657], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447,  15.2209,  -0.4518], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448,  14.6089,  -0.4375], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448,  13.9997,  -0.4230], grad_fn=<DiagBackward>)\n",
      "tensor([143.4607,  18.7529,  -5.2805], grad_fn=<DiagBackward>)\n",
      "tensor([143.4803,  18.2262,  -5.1481], grad_fn=<DiagBackward>)\n",
      "tensor([143.5060,  17.8135,  -5.0622], grad_fn=<DiagBackward>)\n",
      "tensor([143.5310,  17.4081,  -4.9796], grad_fn=<DiagBackward>)\n",
      "tensor([143.5550,  17.0023,  -4.8972], grad_fn=<DiagBackward>)\n",
      "tensor([143.5779,  16.5955,  -4.8147], grad_fn=<DiagBackward>)\n",
      "tensor([143.5996,  16.1877,  -4.7320], grad_fn=<DiagBackward>)\n",
      "tensor([143.6204,  15.7791,  -4.6493], grad_fn=<DiagBackward>)\n",
      "tensor([143.6402,  15.3695,  -4.5665], grad_fn=<DiagBackward>)\n",
      "tensor([143.6589,  14.9592,  -4.4837], grad_fn=<DiagBackward>)\n",
      "tensor([143.6768,  14.5481,  -4.4008], grad_fn=<DiagBackward>)\n",
      "tensor([143.6937,  14.1363,  -4.3179], grad_fn=<DiagBackward>)\n",
      "tensor([143.7098,  13.7238,  -4.2349], grad_fn=<DiagBackward>)\n",
      "tensor([143.7251,  13.3108,  -4.1520], grad_fn=<DiagBackward>)\n",
      "tensor([143.7395,  12.8972,  -4.0691], grad_fn=<DiagBackward>)\n",
      "tensor([143.7532,  12.4831,  -3.9861], grad_fn=<DiagBackward>)\n",
      "tensor([143.7661,  12.0686,  -3.9032], grad_fn=<DiagBackward>)\n",
      "tensor([143.7783,  11.6537,  -3.8204], grad_fn=<DiagBackward>)\n",
      "tensor([143.7898,  11.2385,  -3.7376], grad_fn=<DiagBackward>)\n",
      "tensor([143.8007,  10.8231,  -3.6549], grad_fn=<DiagBackward>)\n",
      "tensor([143.8109,  10.4075,  -3.5723], grad_fn=<DiagBackward>)\n",
      "tensor([143.8205,   9.9917,  -3.4898], grad_fn=<DiagBackward>)\n",
      "tensor([143.8296,   9.5759,  -3.4074], grad_fn=<DiagBackward>)\n",
      "tensor([143.8381,   9.1600,  -3.3251], grad_fn=<DiagBackward>)\n",
      "tensor([143.8461,   8.7442,  -3.2430], grad_fn=<DiagBackward>)\n",
      "tensor([143.8535,   8.3286,  -3.1610], grad_fn=<DiagBackward>)\n",
      "tensor([143.8605,   7.9131,  -3.0792], grad_fn=<DiagBackward>)\n",
      "tensor([143.8671,   7.4979,  -2.9976], grad_fn=<DiagBackward>)\n",
      "tensor([143.8732,   7.0830,  -2.9162], grad_fn=<DiagBackward>)\n",
      "tensor([143.8790,   6.6684,  -2.8351], grad_fn=<DiagBackward>)\n",
      "tensor([143.8843,   6.2544,  -2.7542], grad_fn=<DiagBackward>)\n",
      "tensor([143.8893,   5.8408,  -2.6735], grad_fn=<DiagBackward>)\n",
      "tensor([143.8939,   5.4278,  -2.5931], grad_fn=<DiagBackward>)\n",
      "tensor([143.8981,   5.0155,  -2.5130], grad_fn=<DiagBackward>)\n",
      "tensor([143.9021,   4.6040,  -2.4331], grad_fn=<DiagBackward>)\n",
      "tensor([143.9058,   4.1932,  -2.3536], grad_fn=<DiagBackward>)\n",
      "tensor([143.9093,   3.7832,  -2.2745], grad_fn=<DiagBackward>)\n",
      "tensor([143.9124,   3.3742,  -2.1956], grad_fn=<DiagBackward>)\n",
      "tensor([143.9154,   2.9663,  -2.1171], grad_fn=<DiagBackward>)\n",
      "tensor([143.9180,   2.5593,  -2.0390], grad_fn=<DiagBackward>)\n",
      "tensor([143.9205,   2.1536,  -1.9613], grad_fn=<DiagBackward>)\n",
      "tensor([143.9228,   1.7490,  -1.8840], grad_fn=<DiagBackward>)\n",
      "tensor([143.9250,   1.3458,  -1.8072], grad_fn=<DiagBackward>)\n",
      "tensor([143.9269,   0.9439,  -1.7307], grad_fn=<DiagBackward>)\n",
      "tensor([143.9288,   0.5435,  -1.6547], grad_fn=<DiagBackward>)\n",
      "tensor([143.9303,   0.1445,  -1.5792], grad_fn=<DiagBackward>)\n",
      "tensor([143.9318,  -0.2528,  -1.5041], grad_fn=<DiagBackward>)\n",
      "tensor([143.9332,  -0.6486,  -1.4296], grad_fn=<DiagBackward>)\n",
      "tensor([143.9344,  -1.0425,  -1.3556], grad_fn=<DiagBackward>)\n",
      "tensor([143.9355,  -1.4347,  -1.2821], grad_fn=<DiagBackward>)\n",
      "tensor([143.9367,  -1.8250,  -1.2091], grad_fn=<DiagBackward>)\n",
      "tensor([143.9375,  -2.2134,  -1.1367], grad_fn=<DiagBackward>)\n",
      "tensor([143.9383,  -2.5998,  -1.0648], grad_fn=<DiagBackward>)\n",
      "tensor([143.9391,  -2.9840,  -0.9936], grad_fn=<DiagBackward>)\n",
      "tensor([143.9398,  -3.3662,  -0.9229], grad_fn=<DiagBackward>)\n",
      "tensor([143.9406,  -3.7461,  -0.8529], grad_fn=<DiagBackward>)\n",
      "tensor([143.9411,  -4.1236,  -0.7834], grad_fn=<DiagBackward>)\n",
      "tensor([143.9415,  -4.4989,  -0.7147], grad_fn=<DiagBackward>)\n",
      "tensor([143.9418,  -4.8717,  -0.6465], grad_fn=<DiagBackward>)\n",
      "tensor([143.9422,  -5.2419,  -0.5790], grad_fn=<DiagBackward>)\n",
      "tensor([143.9426,  -5.6096,  -0.5122], grad_fn=<DiagBackward>)\n",
      "tensor([143.9430,  -5.9747,  -0.4461], grad_fn=<DiagBackward>)\n",
      "tensor([143.9434,  -6.3370,  -0.3807], grad_fn=<DiagBackward>)\n",
      "tensor([143.9437,  -6.6966,  -0.3160], grad_fn=<DiagBackward>)\n",
      "tensor([143.9441,  -7.0533,  -0.2521], grad_fn=<DiagBackward>)\n",
      "tensor([143.9443,  -7.4071,  -0.1888], grad_fn=<DiagBackward>)\n",
      "tensor([ 1.4394e+02, -7.7579e+00, -1.2633e-01], grad_fn=<DiagBackward>)\n",
      "tensor([ 1.4394e+02, -8.1057e+00, -6.4592e-02], grad_fn=<DiagBackward>)\n",
      "tensor([ 1.4394e+02, -8.4504e+00, -3.6199e-03], grad_fn=<DiagBackward>)\n",
      "tensor([ 1.4394e+02, -8.7919e+00,  5.6577e-02], grad_fn=<DiagBackward>)\n",
      "tensor([ 1.4394e+02, -9.1302e+00,  1.1599e-01], grad_fn=<DiagBackward>)\n",
      "tensor([143.9443,  -9.4652,   0.1746], grad_fn=<DiagBackward>)\n",
      "tensor([143.9443,  -9.7969,   0.2324], grad_fn=<DiagBackward>)\n",
      "tensor([143.9443, -10.1252,   0.2894], grad_fn=<DiagBackward>)\n",
      "tensor([143.9443, -10.4500,   0.3456], grad_fn=<DiagBackward>)\n",
      "tensor([143.9443, -10.7713,   0.4010], grad_fn=<DiagBackward>)\n",
      "tensor([143.9443, -11.0891,   0.4555], grad_fn=<DiagBackward>)\n",
      "tensor([143.9444, -11.4032,   0.5092], grad_fn=<DiagBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([143.9444, -11.7137,   0.5621], grad_fn=<DiagBackward>)\n",
      "tensor([143.9444, -12.0204,   0.6141], grad_fn=<DiagBackward>)\n",
      "tensor([143.9444, -12.3235,   0.6652], grad_fn=<DiagBackward>)\n",
      "tensor([143.9444, -12.6227,   0.7155], grad_fn=<DiagBackward>)\n",
      "tensor([143.9444, -12.9180,   0.7649], grad_fn=<DiagBackward>)\n",
      "tensor([143.9444, -13.2095,   0.8135], grad_fn=<DiagBackward>)\n",
      "tensor([143.9445, -13.4970,   0.8612], grad_fn=<DiagBackward>)\n",
      "tensor([143.9445, -13.7806,   0.9080], grad_fn=<DiagBackward>)\n",
      "tensor([143.9445, -14.0602,   0.9539], grad_fn=<DiagBackward>)\n",
      "tensor([143.9445, -14.3357,   0.9990], grad_fn=<DiagBackward>)\n",
      "tensor([143.9445, -14.6072,   1.0431], grad_fn=<DiagBackward>)\n",
      "tensor([143.9445, -14.8746,   1.0864], grad_fn=<DiagBackward>)\n",
      "tensor([143.9445, -15.1378,   1.1289], grad_fn=<DiagBackward>)\n",
      "tensor([143.9446, -15.3969,   1.1704], grad_fn=<DiagBackward>)\n",
      "tensor([143.9446, -15.6518,   1.2111], grad_fn=<DiagBackward>)\n",
      "tensor([143.9446, -15.9025,   1.2509], grad_fn=<DiagBackward>)\n",
      "tensor([143.9446, -16.1490,   1.2898], grad_fn=<DiagBackward>)\n",
      "tensor([143.9446, -16.3912,   1.3278], grad_fn=<DiagBackward>)\n",
      "tensor([143.9446, -16.6292,   1.3650], grad_fn=<DiagBackward>)\n",
      "tensor([143.9446, -16.8629,   1.4013], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -17.0924,   1.4368], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -17.3175,   1.4713], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -17.5384,   1.5051], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -17.7549,   1.5380], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -17.9672,   1.5700], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -18.1751,   1.6012], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -18.3788,   1.6316], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -18.5782,   1.6612], grad_fn=<DiagBackward>)\n",
      "tensor([143.9447, -18.7733,   1.6899], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -18.9641,   1.7178], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -19.1506,   1.7450], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -19.3329,   1.7713], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -19.5110,   1.7969], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -19.6849,   1.8217], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -19.8545,   1.8457], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -20.0200,   1.8690], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -20.1814,   1.8916], grad_fn=<DiagBackward>)\n",
      "tensor([143.9448, -20.3387,   1.9134], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -20.4918,   1.9345], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -20.6410,   1.9549], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -20.7861,   1.9746], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -20.9272,   1.9936], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -21.0644,   2.0120], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -21.1977,   2.0297], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -21.3272,   2.0467], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -21.4528,   2.0631], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -21.5747,   2.0789], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -21.6929,   2.0941], grad_fn=<DiagBackward>)\n",
      "tensor([143.9449, -21.8074,   2.1087], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -21.9182,   2.1228], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.0256,   2.1362], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.1294,   2.1491], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.2298,   2.1615], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.3267,   2.1734], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.4204,   2.1847], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.5107,   2.1956], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.5979,   2.2059], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.6819,   2.2158], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.7628,   2.2253], grad_fn=<DiagBackward>)\n",
      "tensor([143.9450, -22.8407,   2.2343], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -22.9156,   2.2429], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -22.9876,   2.2511], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.0569,   2.2589], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.1233,   2.2662], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.1870,   2.2733], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.2481,   2.2799], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.3067,   2.2863], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.3627,   2.2922], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.4164,   2.2979], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.4677,   2.3033], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.5166,   2.3083], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.5634,   2.3131], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.6080,   2.3176], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.6505,   2.3219], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.6910,   2.3259], grad_fn=<DiagBackward>)\n",
      "tensor([143.9451, -23.7295,   2.3296], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.7661,   2.3332], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.8009,   2.3365], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.8340,   2.3396], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.8653,   2.3425], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.8950,   2.3452], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.9231,   2.3478], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.9497,   2.3502], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.9749,   2.3524], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -23.9987,   2.3545], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -24.0211,   2.3564], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -24.0422,   2.3582], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -24.0621,   2.3599], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -24.0808,   2.3614], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -24.0984,   2.3628], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -24.1150,   2.3642], grad_fn=<DiagBackward>)\n",
      "tensor([143.9452, -24.1305,   2.3654], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.1450,   2.3665], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.1586,   2.3676], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.1714,   2.3686], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.1833,   2.3694], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.1944,   2.3703], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2048,   2.3710], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2144,   2.3717], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2234,   2.3723], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2317,   2.3729], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2395,   2.3734], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2467,   2.3739], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2533,   2.3743], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2595,   2.3747], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2652,   2.3751], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2704,   2.3754], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2753,   2.3757], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2797,   2.3760], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2838,   2.3762], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2876,   2.3764], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2911,   2.3766], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2942,   2.3768], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2971,   2.3770], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.2998,   2.3771], grad_fn=<DiagBackward>)\n",
      "tensor([143.9453, -24.3022,   2.3772], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3044,   2.3774], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3064,   2.3775], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3082,   2.3775], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3099,   2.3776], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3114,   2.3777], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3127,   2.3778], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3140,   2.3778], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3151,   2.3779], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3161,   2.3779], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3169,   2.3779], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3178,   2.3780], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3185,   2.3780], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3191,   2.3780], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3197,   2.3781], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3202,   2.3781], grad_fn=<DiagBackward>)\n",
      "tensor([143.9454, -24.3207,   2.3781], grad_fn=<DiagBackward>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([A0], lr = 0.1)\n",
    "target = eigvals(A1)\n",
    "print(target)\n",
    "\n",
    "for _ in range (10000):\n",
    "    \n",
    "    current_eigen = eigvals(A0)\n",
    "    \n",
    "    #loss =   weighted_norm(current_eigen, mu)+pen# calculate loss\n",
    "    loss =   weighted_norm(current_eigen, target)\n",
    "\n",
    "    optimizer.zero_grad()  # clear previous gradients\n",
    "    loss.backward()        # compute gradients of all variables wrt loss\n",
    "\n",
    "    optimizer.step()\n",
    "    if _ % 25 == 0:\n",
    "        print (current_eigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(A0.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm([1.0,2.0,3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1.0,2.0,3.0], requires_grad=True).norm().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
